---
layout: post
title:  "sqoop 1.4.6-cdh5.11.0 安装和配置"
desc: "sqoop 1.4.6-cdh5.11.0 安装和配置"
keywords: "sqoop 1.4.6-cdh5.11.0 安装和配置,sqoop,kinglyjn"
date: 2018-04-06
categories: [Java]
tags: [java]
icon: fa-coffee
---

>[说明文档地址](http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.6-cdh5.11.0)

### 下载和安装

```shell
# 下载
$ wget http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.6-cdh5.11.0.tar.gz

# 解压安装，配置环境变量
# (略)

# 配置 conf/sqoop-env.sh
$ cp sqoop-env-template.sh sqoop-env.sh
$ vim sqoop-env.sh

# 测试是否安装成功
$ sqoop help
$ sqoop help import
$ sqoop version

# [注]
# 如果抽取 mysql 数据，需要有 mysql 驱动包的支持
$ cp mysql-connector-java-5.1.38.jar $SQOOP_HOME/lib
# 如果抽取 mongodb 数据，需要有 mongodb 驱动包的支持
$ cp mongo-java-driver-3.4.2.jar $SQOOP_HOME/lib
```

<br>



### sqoop import & import-all-tables

```shell
#################
# mysql -> hdfs
#################

# 导入单表
# --connect 连接串中必须指定到数据库名
# --incremental 表示增量导入，支持 append 和 lastmodified 两种模式
# append 表示导入比 检查字段(一般为id) check-column 的 last-value值 大的增量数据
# lastmodified 表示导入比 检查字段(一般为时间戳) check-column 的 last-value值 大的数据
# --target-dir 表示导入 hdfs 的路径，该路径事先存不存在都可以
# -m 表示map任务的个数
# –-bindir 指定生成的java文件、编译成的class文件及将生成文件打包为JAR的JAR包文件输出路径，默认在/tmp
# –-outdir 指定生成的java文件存放路径，默认在当前用户目录下
$ sqoop import \
--connect jdbc:mysql://dbserver:3306/sqoopui \
--driver com.mysql.jdbc.Driver \
--username root \
--P \
--table t_jdbc_connection \
--target-dir /user/ubuntu/test/bak/t_jdbc_connection \
--where "id<1000" \
--incremental append \
--check-column id \
--last-value 20 \
--mapreduce-job-name jobname01 \
-m 1 \
--bindir ~/1 \
--outdir ~/2 \

# 整库导入
# 整库导入需要满足三个条件，即
# 每张表都有主键，每张表所有字段必须全部导入，每张表必须使用默认分隔列，且WHERE子句无任何强加的条件
# --table, --split-by, --columns, 和 --where 参数在sqoop-import-all-tables命令中是不合法的
# --exclude-tables：可以用来排除导入某个表。具体的导入用法和单表导入差不多
# 导出数据的目录存在 hdfs 当前用户目录下面，每张表的数据都存在表名所在的目录
$ sqoop import-all-tables \
--connect jdbc:mysql://dbserver:3306/sqoopui \
--driver com.mysql.jdbc.Driver \
--username root \
-password xxxx \
-m 1 \

# 查询导入
# where子句中最后需要跟 and $CONDITIONS 或者 or $CONDITIONS 结束标志
# --target-dir 目录事先必须不存在
$ sqoop import \
--query 'SELECT a.*, b.* FROM a LEFT JOIN b on a.id=b.id WHERE a.id>10 and $CONDITIONS' \
--split-by a.id \
--target-dir /user/ubuntu/test/bak/ab \



# [注]
# 可能遇到的问题
# 问题1：sqoop import导入时报java.lang.ClassNotFoundException: org.json.JSONObject 错误
# 这是因为sqoop缺少java-json.jar包
$ curl http://www.java2s.com/Code/Jar/j/Downloadjavajsonjar.htm
$ wget http://www.java2s.com/Code/JarDownload/java-json/java-json.jar.zip
$ cp java-json.jar $SQOOP_HOME/lib  #或者
$ cp java-json.jar /opt/cloudera/parcels/CDH-5.11.0-1.cdh5.11.0.p0.34/lib/sqoop/lib

# 问题2：root用户写入HDFS文件错误 "Permission denied: user=root"
# 因为在使用sqoop导入HDFS文件时，使用的是root用户，没有写hdfs文件的权限。
# CDH安装时创建了hdfs用户，应使用hdfs用户登录，再时行sqoop导入
$ su - hdfs

# 问题3：其它hadoop节点不连接MySql "is not allowed to connect to this MySQL server"
# 这是因为客户端没有访问mysql的权限，修改sqoop用户的客户端访问权限。
# --登录mysql服务器
$ mysql -uroot -proot 
mysql> grant all privileges on *.* to 'sqoop'@'%' identified by 'sqoop' with grant option;
```

<br>



### sqoop export

```shell
#################
# hdfs -> mysql
#################

# 导出到mysql表
# 注意：导出的字段必须和导出表中的字段完全一致，不然会导出失败！
# update-key update-mode 文件中存在的记录做更新，不存在的记录则插入
# update-mode 有两种，一种是updateonly，一种是 allowinsert
# columns 指定导出到 mysql 的列
$ sqoop export \
--connect jdbc:mysql://dbserver:3306/sqoopui \
--driver com.mysql.jdbc.Driver \
--username root \
-P \
--table t_jdbc_connection_bak \
--export-dir /user/ubuntu/test/bak/t_jdbc_connection \
--verbose \
```

 