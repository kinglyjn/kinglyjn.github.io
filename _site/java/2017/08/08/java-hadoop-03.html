<!DOCTYPE html>
<html>
	
	    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <meta content="hadoop完全分布式环境的搭建以及HDFS和YARN的HA配置（三）" name="description">
  
  
    <meta name="keywords" content="hadoop完全分布式环境的搭建以及HDFS和YARN的HA配置（三）,hadoop,kinglyjn">
  
  <meta name="author" content="KinglyJn">

  <title>
    
        KinglyJn|hadoop完全分布式环境的搭建以及HDFS和YARN的HA配置（三）
    
  </title>
  <!-- favicon -->
  <link rel="shortcut icon" href="static/img/favicon.ico">


  <!-- Third-party CSS -->
  <link href="/bower_components/normalize-css/normalize.min.css" rel="stylesheet">
  <link href="/bower_components/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="/bower_components/animate.css/animate.min.css" rel="stylesheet">
  <link href="/bower_components/components-font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="/static/font-mfizz/font-mfizz.css" rel="stylesheet">
  <!-- <link href="/bower_components/toastr/toastr.min.css" rel="stylesheet"> -->
  <link href="/bower_components/jquery.gritter/css/jquery.gritter.css" rel="stylesheet">
  <link rel="stylesheet" href="/search/css/cb-search.css">

  <!-- Custom styles for this template -->
  <link href="/static/css/style.min.css" rel="stylesheet">
  <link href="/static/css/pygments.css" rel="stylesheet">

  <!-- Scripts -->
  <script src="/bower_components/jquery/dist/jquery.min.js"></script>
  <script src="/search/js/bootstrap3-typeahead.min.js"></script>

  <!-- cb-search -->
  <script src="/search/js/cb-search.js"></script>
  <script>
    $(function(){
        $("pre").css('display','block');
    });
  </script>
  <!-- Mainly scripts -->
  <script src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
  <script src="/bower_components/metisMenu/dist/metisMenu.min.js"></script>
  <script src="/bower_components/jquery-slimscroll/jquery.slimscroll.min.js"></script>

  <!-- Peity -->
  <script src="/bower_components/peity/jquery.peity.min.js"></script>

  <script src="/bower_components/PACE/pace.min.js"></script>
  <script src="/bower_components/wow/dist/wow.min.js"></script>
  <!-- Custom and plugin javascript -->
  <script src="/static/js/inspinia.js"></script>

  <!-- Rickshaw -->
  <script src="/bower_components/rickshaw/vendor/d3.v3.js"></script>
  <script src="/bower_components/rickshaw/rickshaw.min.js"></script>


  <!-- jPages -->
  <script src="/static/js/jPages.js"></script>
  <script src="/static/js/js.js"></script>
  <script type="text/javascript">
        $(function(){
          /* initiate the plugin */
          $("div.pag-holder").jPages({
              containerID  : "pag-itemContainer",
              perPage      : 10,  /* num of items per page */
              startPage    : 1,
              startRange   : 1,
              midRange     : 3,
              endRange     : 1
          });

          $("div.pag-jump button").click(function(){
            var page = parseInt($("div.pag-jump input").val());
            $("div.pag-holder").jPages(page);
          });

          $("div.pag-jump input").on("keypress", function(){
            var e=e||window.event;
            if (e.keyCode == 13) {
                var page = parseInt($("div.pag-jump input").val());
                $("div.pag-holder").jPages(page);
            } 
          });
      });
  </script>

<!-- GrowingIO -->

  <script>
    var _vds = _vds || [];
    window._vds = _vds;
    (function(){
      _vds.push(['setAccountId', 'a49d4901c7853da9']);
      (function() {
        var vds = document.createElement('script');
        vds.type='text/javascript';
        vds.async = true;
        vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(vds, s);
      })();
    })();
  </script>


</head>

	


<body id="page-top" class="landing-page">

	
	    

<!--修复手机端横轴方向左右滑动BUG-->
<style type="text/css">
    .landing-page .row {
        margin-left: 0px;
        margin-right: 0px;
    }
</style>

<div class="search-tool"
      style="position: fixed; top: 0px ; bottom: 0px; left: 0px; right:  0px; opacity: 0.95; background-color: #111111; z-index: 9999; display: none;">
    <input type="text" class="form-control search-content" id="search-content" style="position: fixed; top: 60px" placeholder="Search Blog">

    <div style="position: fixed; top: 16px; right: 16px; z-index: 9999;">
        <img src="/search/img/cb-close.png" id="close-btn"/>
    </div>
</div>

<div style="position: fixed; right: 16px; bottom: 20px; z-index: 9999;">
    <img src="/search/img/cb-search.png"  id="search-btn"  title="Double click Ctrl"/>
</div>

<div class="navbar-wrapper">
        <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">
                <div class="navbar-header page-scroll">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">KinglyJn</a>
                </div>
                <div id="navbar" class="navbar-collapse collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a class="page-scroll" href="/blog/"></a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/blog/">Blog</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/linux/">Linux</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/cloud/">Cloud</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/java/">Java</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/c/">C</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/py/">Py</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/php/">PHP</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/db/">DB</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/htmlx/">HTMLX</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/life/">Life</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/art/">Art</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/other/">Other</a></li>
                        
                    </ul>
                </div>
            </div>
        </nav>
</div>
<div id="inSlider" class="carousel carousel-fade" data-ride="carousel">
    <div style="position:absolute;float:left;left:25%;z-index:15;width:50%;margin-bottom:18%;bottom:0;text-align:center;list-style:none;">
        <span style="color:white;font-size:24px;">以平实之心写作</span><br>
        <span style="color:white;font-size:13px;">writing with simple heart ♬. </span>
    </div>
    <!--
    <ol class="carousel-indicators">
        <li data-target="#inSlider" data-slide-to="0" class="active"></li>
        <li data-target="#inSlider" data-slide-to="1"></li>
    </ol>
    -->
    <div class="carousel-inner" role="listbox">
        <div class="item active">
            <div class="container">
                <div class="carousel-caption">
                </div>
                <div class="carousel-image wow zoomIn">
                    <!-- <img src="static/img/landing/laptop.png" alt="laptop"/> -->
                </div>
            </div>
            <!-- Set background for slide in css -->
            <div class="header-back blog-one"></div>
        </div>
        <!--
        <div class="item">
            <div class="container">
                <div class="carousel-caption blank">
                </div>
            </div>
            Set background for slide in css
            <div class="header-back two"></div>
        </div>
        -->
    </div>
    <!--
    <a class="left carousel-control" href="#inSlider" role="button" data-slide="prev">
        <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
    </a>
    <a class="right carousel-control" href="#inSlider" role="button" data-slide="next">
        <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
    </a>
    -->
</div>


	

    <div class="wrapper wrapper-content  animated fadeInRight article">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1">
            <div class="ibox">
                <div class="ibox-content">
                    <div class="pull-right">
                    	
                        	<button class="btn btn-white btn-xs" type="button">Java</button>
                        
                    </div>
                    <div class="text-center article-title" style="margin-bottom:50px;">
                        <h1>
                            hadoop完全分布式环境的搭建以及HDFS和YARN的HA配置（三）
                        </h1>
                        <a href="http://www.keyllo.com/studio/">
                            <span class="text-muted"><i class="fa fa-user"></i> KinglyJn</span>
                        </a>
                        &nbsp;&nbsp;&nbsp;&nbsp;
                        <span class="text-muted"><i class="fa fa-clock-o"></i> 2017-08-08</span>
                    </div>
                    	<h3 id="前期准备">前期准备</h3>

<p>对机器的配置</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>numbusz</th>
      <th>supervisor01z</th>
      <th>supervisor02z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CPU</td>
      <td>20核</td>
      <td>20核</td>
      <td>20核</td>
    </tr>
    <tr>
      <td>内存</td>
      <td>50G</td>
      <td>50G</td>
      <td>50G</td>
    </tr>
    <tr>
      <td>硬盘</td>
      <td>100TB</td>
      <td>100TB</td>
      <td>100TB</td>
    </tr>
  </tbody>
</table>

<p>对机器的服务进行规划</p>

<pre><code class="language-dedault">numbusz                supervisor01z                supervisor02z             备注
-----------------------------------------------------------------------------------------
namenode              secondarynamenode             redourcemanager         
datanode              datanode                      datanode                主要消耗硬盘
nodemanager           nodemanager                   nodemanager             主要消耗CPU            
historyserver
</code></pre>

<blockquote>
  <p>常见的hadoop的默认web端口：</p>

  <p>yarn外部管理界面端口：8088</p>

  <p>HDFS外部管理界面端口：50070</p>

  <p>secondarynamenode外部管理界面端口：50090</p>
</blockquote>

<p><br /></p>

<h3 id="配置和搭建过程">配置和搭建过程</h3>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c">#0. 设置各个节点之间的ssh双向无密码登录</span>
<span class="c">#为了统一起见，这里我们在都在/opt目录下创建统一文件夹方便安装和管理</span>
<span class="c">#并且安装hadoop 和 jdk统一在 /opt/modules 目录下</span>
<span class="c">#当在一台主机上所有的安装配置做完之后，只需要使用scp命令进行文件夹的分发即可</span>
<span class="gp">$ </span><span class="nb">cd</span> /opt
<span class="gp">$ </span>sudo mkdir -p datas  modules  software  tools
<span class="gp">$ </span>sudo chown -R ubuntu:ubuntu datas  modules  software  tools

<span class="c">#1. 在一台机器上（比如nimbusz）解压hadoop，删除没用的文档文件</span>
<span class="gp">$ </span>tar -zxvf hadoop-2.5.0.tar.gz -C /opt/modules
<span class="gp">$ </span>rm -rf /opt/modules/hadoop-2.5.0/share/doc

<span class="c">#2. 配置基本 *.env 环境的java环境，主要配置以下三个配置文件，并查看是否生效：</span>
hadoop-env.sh
mapred-env.sh
yarn-env.sh
<span class="gp">$ </span>bin/hadoop


<span class="c">#3. 配置 *.site.xml文件，主要包含以下4+1个配置文件：</span>
core-site.xml
hdfs-site.xml
slaves
mapred-site.xml
yarn-site.xml

<span class="c">#3.1 配置core-site.xml</span>
&lt;configuration&gt;
	&lt;!--hdfs主从节点通信默认端口号为8020--&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://nimbusz:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--hdfs的namenode节点元数据的镜像文件--&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/modules/hadoop-2.5.0/data/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--设置一个hadoop的web静态用户名<span class="o">(</span>默认为dr.who<span class="o">)</span>--&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;ubuntu&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

<span class="c">#3.2 配置hdfs-site.xml</span>
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;supervisor01z:50090&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

<span class="c">#3.3 配置slaves</span>
<span class="c">#严格来讲，slaves文件存储的并不是真正的datanode节点，它唯一的作用是在集群操作的时候要正对这个文件去ssh处理。我们在start-all.sh、start-dfs.sh、start-yarn.sh的时候，通过ssh向远程服务器发送指令，将远程服务器启动。至于节点是不是datanode节点，取决于dfs.hosts和dfs.hosts.exclude两个参数。</span>
nimbusz
supervisor01z
supervisor02z

<span class="c">#3.4 配置mapred-site.xml</span>
&lt;configuration&gt;
	&lt;!--指定mapreduce运行在yarn上--&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;nimbusz:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;nimbusz:19888&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

<span class="c">#3.5 配置yarn-site.xml</span>
&lt;configuration&gt;
	&lt;!--启动mapreduce_shuffle服务以支持运行mapreduce程序--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--指定resourcemanager所在的机器--&gt;
    &lt;!--如果没有指定，则在集群的哪一台机器启动resourcemanager，则就认为哪一台机器就是RMr--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;supervisor02z&lt;/value&gt;
    &lt;/property&gt;	
    &lt;!--如果有多张网卡，需要配置此选项，才能打开web界面--&gt;
    &lt;property&gt;
    	&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
    	&lt;value&gt;master:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--启用hadoop的日志聚集功能<span class="o">(</span>默认false<span class="o">)</span>--&gt;
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--日志保存在HDFS上的期限<span class="o">(</span>默认为-1，这里配置的是一周<span class="o">)</span>--&gt;
        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
        &lt;value&gt;604800&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;


<span class="c">#4. 将配置好的jdk和hadoop环境分发到各个节点，并在各个节点上配置好jdk和hadoop的环境变量</span>
<span class="gp">$ </span>sudo scp datas  modules  software  tools ubuntu@supervsior01z:/opt
<span class="gp">$ </span>sudo scp datas  modules  software  tools ubuntu@supervsior02z:/opt
<span class="gp">$ </span>vim /etc/profile
<span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/opt/modules/jdk1.8.0_144
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$JAVA_HOME</span>/bin


<span class="c">#5. 分别在各个节点初始格式化namenode</span>
<span class="gp">$ </span>bin/hdfs namenode -format


<span class="c">#6. 在nimbusz启动namenode、在supervisor01z启动secondarynamenode、</span>
<span class="c">#   在nimbusz、supervisor01z、supervisor02z分别启动datanode；</span>
<span class="gp">$ </span>sbin/hadoop-daemon.sh start namenode
<span class="gp">$ </span>sbin/hadoop-daemon.sh start secondarynamenode
<span class="gp">$ </span>sbin/hadoop-daemon.sh start datanode
<span class="c"># 测试HDFS工作正常</span>
<span class="gp">$ </span>bin/hdfs dfs -mkdir -p /user/ubuntu/wc/input
<span class="gp">$ </span>curl http://nimbusz:50070/explorer.html
<span class="gp">$ </span>bin/hdfs dfs -put /opt/datas/wc.txt /user/ubuntu/wc/input
<span class="gp">$ </span>bin/hdfs dfs -text /user/ubuntu/wc/input/wc.txt
<span class="c"># 测试secondarynamenode正常</span>
<span class="gp">$ </span>curl http://supervisor01z:50090

<span class="c"># 在supervisor02z启动redourcemanager、</span>
<span class="c"># 在nimbusz、supervisor01z、supervisor02z分别启动nodemanager；</span>
<span class="c"># 在nimbusz启动historyserver</span>
<span class="gp">$ </span>sbin/yarn-daemon.sh start resourcemanager
<span class="gp">$ </span>sbin/yarn-daemon.sh start nodemanager
<span class="gp">$ </span>sbin/mr-jobhistory-daemon.sh start historyserver
<span class="c"># 测试MR在yarn上运行正常</span>
<span class="gp">$ </span>bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /user/ubuntu/wc/input /user/ubuntu/wc/output
<span class="gp">$ </span>curl http://nimbusz:8088/explorer.html
<span class="gp">$ </span>bin/hdfs dfs -text /user/ubuntu/wc/output/part<span class="k">*</span>
</code></pre>
</div>

<p><br /></p>

<h3 id="快捷启动和关闭hadoop集群">快捷启动和关闭hadoop集群</h3>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 前提是已经设置各个节点之间的ssh双向无密码登录</span>
<span class="c">#1.1 在任意一个节点上关闭HDFS，执行下面命令将会</span>
<span class="c">#关闭nimbusz的namenode，关闭supervisor01z的secondarynamenode，关闭各个节点的datanode</span>
<span class="gp">$ </span>sbin/stop-dfs.sh 

<span class="c">#1.2 在任意一个节点上关闭yarn，执行下面的命令将会</span>
<span class="c">#关闭supervisor02z的resourcemanager，关闭各个节点的nodemanager</span>
<span class="gp">$ </span>sbin/stop-yarn.sh 

<span class="c">#1.3 在nimbusz上关闭historyserver</span>
<span class="gp">$ </span>sbin/mr-jobhistory-daemon.sh stop historyserver


<span class="c">#启动hadoop集群</span>
<span class="c">#2.1 在nimbusz节点执行</span>
<span class="gp">$ </span>sbin/start-dfs.sh

<span class="c">#2.2 在supervisor02z节点执行</span>
<span class="gp">$ </span>sbin/start-yarn.sh 

<span class="c">#2.3 在nimbusz上执行</span>
<span class="gp">$ </span>sbin/mr-jobhistory-daemon.sh start historyserver
</code></pre>
</div>

<p><br /></p>

<h3 id="集群的时间同步服务ntp服务">集群的时间同步服务（NTP服务）</h3>

<ol>
  <li>由于linux服务器运行时间久了会造成时间上的误差，需要我们配置各个节点之间的时间同步服务。</li>
  <li>国家授时中心，可以通过互联网去连接这些时间同步服务器，但是如果不能联网，只能通过自己的内部服务器实现时间同步功能</li>
  <li>内网时间同步可以通过在内网集群中找到一台机器作为时间同步基准服务器</li>
</ol>

<p>以下是ubuntu系统安装和配置时间同步服务的步骤：(以下是使用ntp作为基准服务器，其他节点使用ntpdate定时同步ntp基准服务器的时间；由于ntp既是服务器，也可以作为客户端，所以也可以只使用ntp完成时间同步的需求，这也是推荐的做法)</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c">#1.1 在基准节点安装ntp服务(比如我们在nimbusz，这里安装的时候要确保联网)</span>
<span class="gp">$ </span>sudo vim 
<span class="gp">$ </span>sudo apt-get install ntp

<span class="c">#1.2 安装完成之后我们来看一下服务是否启动，[+]表示已启动</span>
<span class="gp">$ </span>service --status-all |grep ntp
<span class="o">[</span> + <span class="o">]</span>  ntp

<span class="c">#1.3 修改ntp服务的配置文件/etc/ntp.conf</span>
<span class="gp">$ </span>sudo vim /etc/ntp.conf
	<span class="c">#第一处：允许这个网段的对时请求</span>
    restrict 172.16.127.0 mask 255.255.255.0 nomodify notrap
    
    <span class="c">#第二处：由于是内网环境，就不需要这些服务配置，注释掉</span>
    <span class="c">#server 0.ubuntu.pool.ntp.org</span>
    <span class="c">#server 1.ubuntu.pool.ntp.org...</span>
    
    <span class="c">#第三处：ntp server 提供的本地服务</span>
    <span class="c">#让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的</span>
    <span class="c">#server都不可用时，将使用local时间作为ntp服务提供给ntp客户端</span>
    <span class="c">#上层ntp server，在客户端打开这个选项</span>
    <span class="c">#server nimbusz prefer</span>
    server 127.127.1.0
    fudge 127.127.1.0 stratum 10
    
<span class="c">#1.4 重启ntp服务，并设置ntp自动开机重启</span>
<span class="gp">$ </span>sudo service ntp restart
<span class="gp">$ </span>sudo sysv-rc-conf


<span class="c">#2.1 在其他需要同步基准服务器的节点上，计划一个crontab，用来进行时间同步(这里使用sudo，也可直接切su -)</span>
<span class="gp">$ </span>sudo crontab -e
	<span class="c">#sync time</span>
	0-59/10 <span class="k">*</span> <span class="k">*</span> <span class="k">*</span> <span class="k">*</span> /usr/sbin/ntpdate nimbusz
<span class="gp">$ </span>sudo crontab -l
<span class="gp">$ </span>sudo ntpdate nimbusz
<span class="gp">$ </span>sudo hwclock --systohc <span class="c">#同步系统时间到硬件</span>
<span class="gp">$ </span>sudo hwclock --show <span class="c">#查看硬件时间</span>

<span class="c">#2.2 除了同步系统时间，在设置同步BIOS的时间：</span>
hwclock --show 		显示bios时间
hwclock --systohc 	将系统时间写入bios
hwclock --hctosys 	将bios时间写入系统
hwclock --help 		显示帮助
</code></pre>
</div>

<blockquote>
  <p>注：安装sysv-rc-conf启动项管理服务</p>

  <p>$ sudo apt-get install sysv-rc-conf</p>

  <p>$ sudo sysv-rc-conf</p>

  <p>例如在大多数linux操作系统下一共有如下6个典型的运行级别：</p>

  <p>0 停机</p>

  <p>1 单用户，Does not configure network interfaces, start daemons, or allow non-root logins</p>

  <p>2 多用户，无网络连接 Does not configure network interfaces or start daemons</p>

  <p>3 多用户，启动网络连接 Starts the system normally.</p>

  <p>4 用户自定义</p>

  <p>5 多用户带图形界面</p>

  <p>6 重启</p>

  <p>查看当前系统的运行级别可以使用命令：$ runlevel</p>

  <p>切换运行级别：init [0123456Ss]  如：用 init 0 命令关机；用 init 6 命令重新启动</p>

  <p>Linux 系统主要启动步骤：</p>

  <pre><code class="language-default">1. 读取 MBR 的信息,启动 Boot Manager
        Windows 使用 NTLDR 作为 Boot Manager,如果您的系统中安装多个
        版本的 Windows,您就需要在 NTLDR 中选择您要进入的系统。
        Linux 通常使用功能强大,配置灵活的 GRUB 作为 Boot Manager。
2. 加载系统内核,启动 init 进程
        init 进程是 Linux 的根进程,所有的系统进程都是它的子进程。
3. init 进程读取 /etc/inittab 文件中的信息,并进入预设的运行级别,
   按顺序运行该运行级别对应文件夹下的脚本。脚本通常以 start 参数启
   动,并指向一个系统中的程序。
        通常情况下, /etc/rcS.d/ 目录下的启动脚本首先被执行,然后是
        /etc/rcN.d/ 目录。例如您设定的运行级别为 3,那么它对应的启动
        目录为 /etc/rc3.d/ 。
4. 根据 /etc/rcS.d/ 文件夹中对应的脚本启动 Xwindow 服务器 xorg
        Xwindow 为 Linux 下的图形用户界面系统。
5. 启动登录管理器,等待用户登录
        Ubuntu 系统默认使用 GDM 作为登录管理器,您在登录管理器界面中
        输入用户名和密码后,便可以登录系统。(您可以在 /etc/rc3.d/
        文件夹中找到一个名为 S13gdm 的链接)
</code></pre>
</blockquote>

<p><br /></p>

<h3 id="zk">ZK</h3>

<ul>
  <li>分布式架构</li>
  <li>功能：同步&amp;选举</li>
  <li>节点数目：2n+1（n为允许宕机的机器）</li>
  <li>数据结构：节点树的结构，每个节点都是一个znode，存放在内存中，本地磁盘中会有备份。</li>
</ul>

<p>下面是zk的基本配置：可 <a href="http://www.page.keyllo.com/linux/2017/07/26/zookeeper-base01.html">参考</a></p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="nv">tickTime</span><span class="o">=</span>2000
<span class="nv">initLimit</span><span class="o">=</span>10
<span class="nv">syncLimit</span><span class="o">=</span>5

<span class="nv">dataDir</span><span class="o">=</span>/home/ubuntu/zookeeper-3.4.6/zkdata
<span class="nv">dataLogDir</span><span class="o">=</span>/home/ubuntu/zookeeper-3.4.6/logs
<span class="nv">clientPort</span><span class="o">=</span>2181

server.1<span class="o">=</span>nimbusz:2888:3888
server.2<span class="o">=</span>supervisor01z:2888:3888
server.3<span class="o">=</span>supervisor02z:2888:3888
</code></pre>
</div>

<p><br /></p>

<h3 id="解决hdfs的单点故障-hdfs-ha-架构">解决hdfs的单点故障-HDFS HA 架构</h3>

<p>在hadoop2.0之前，namenode存在单点故障（SPOF），对于只有一个namenode节点的hdfs集群，当namenode宕机之后，则整个集群将无法使用，直到namenode重新启动。HA架构通常有两个namenode。</p>

<ol>
  <li>
    <p>元数据同步需要保证两个namenode内存中存储的文件系统元数据是一致的</p>

    <p>思路：namenode的启动过程</p>

    <ul>
      <li>读取fsimage和edits文件，读取后生成新的fsimage和edits文件</li>
      <li>另一个namenode同样需要去读取这两个文件，变化后的edits文件同样需要读取</li>
      <li>注册心跳、块的报告也需要向另一个namenode实时地进行汇报</li>
    </ul>
  </li>
  <li>
    <p>日志文件的安全性</p>

    <ul>
      <li>cloudera公司提出了分布式日志存储方案</li>
      <li>找到一个datanode节点的目录，只要日志在2n+1个节点的n+1个节点存储成功即可，journalnode日志节点。这时候seconarynamenode就没有存在的必要了，HA架构中不能使用secondarynamenode！</li>
      <li>日志文件被写了多份存储在HDFS上，为了保证高可用，datanode需要是奇数个</li>
      <li>当然日志文件也可以存储在zk上，但是不适合日志量很大的情形</li>
    </ul>
  </li>
  <li>
    <p>通过代理来让客户端判断现在对外提供服务的是哪一台namenode。需要保证同一时间下，对外提供服务的只能是其中一个namenode节点，这里会涉及到一个<code class="highlighter-rouge">隔离的方法</code>。</p>
  </li>
</ol>

<p>手动版的 HDFS HA 配置、启动、使用过程：<a href="http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">参考</a></p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c">#配置HDFS HA的要点：</span>
<span class="c">#编辑日志文件（share edits），通过journalnode节点配置（最少3台）</span>
<span class="c">#配置两个namenode（active、standby）</span>
<span class="c">#HDFS客户端代理（client proxy）</span>
<span class="c">#隔离（fence），同一时刻仅仅有一个namenode对外提供服务</span>

<span class="c">#0.0 HDFS HA 集群的规划：</span>
nimbusz             supervisor01z           supervisor02z
---------------------------------------------------------
journalnode         journalnode             journalnode
namenode（active）   namenode（standby）						
datanode            datanode                datanode



<span class="c">#1.1 core-site.xml</span>
&lt;configuration&gt;
	&lt;property&gt;
		&lt;!--执行HDFS的命名空间--&gt;
     	&lt;name&gt;fs.defaultFS&lt;/name&gt;
      	&lt;value&gt;hdfs://ns1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/modules/hadoop-2.5.0/data/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;ubuntu&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;


<span class="c">#1.2 hdfs-site.xml</span>
&lt;configuration&gt;
	&lt;property&gt;
		&lt;!--指定命nameservices的名空间的名称--&gt;
      	&lt;name&gt;dfs.nameservices&lt;/name&gt;
      	&lt;value&gt;ns1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定两个namenode的名称--&gt;
      	&lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;
      	&lt;value&gt;nn1,nn2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定nn1的主机位置--&gt;
      	&lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;
        &lt;value&gt;nimbusz:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定nn2的主机位置--&gt;
      	&lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;
      	&lt;value&gt;supervisor01z:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定nn1的web访问主机位置--&gt;
     	&lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;
      	&lt;value&gt;nimbusz:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定nn2的web访问主机位置--&gt;
      	&lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;
      	&lt;value&gt;supervisor01z:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定日志节点的主机、端口和命名空间--&gt;
     	&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
      	&lt;value&gt;qjournal://nimbusz:8485;supervisor01z:8485;supervisor02z:8485/ns1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定日志节点真正存储的路径--&gt;
    	&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
    	&lt;value&gt;/opt/modules/hadoop-2.5.0/data/jn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--指定客户端代理访问的配置--&gt;
      	&lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;
      	&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha
      			.ConfiguredFailoverProxyProvider&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--使用ssh协议的方式将两个namenode进行隔离--&gt;
      	&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
      	&lt;value&gt;sshfence&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;!--使用ssh协议的方式将两个namenode进行隔离--&gt;
      	&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
      	&lt;value&gt;/home/ubuntu/.ssh/id_rsa&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;


<span class="c">#2.1 先分别启动三个journalnode节点</span>
<span class="c"># 注：在各个JournalNode机器上执行命令“hadoop-daemon.sh  journalnode”。</span>
<span class="c"># 如果是一个新的HDFS集群，还要首先执行格式化命令“hdfs  namenode  -format”，紧接着启动本NameNode进程。</span>
<span class="c"># 如果存在一个已经格式化过的NameNode，并且已经启动了。那么应该把该NameNode的数据同步到另一个没有格式化的NameNode。在未格式化过的NameNode上执行命令“hdfs  namenode  -bootstrapStandby”。</span>
<span class="c"># 如果是把一个非HA集群转成HA集群，应该运行命令“hdfs –initializeSharedEdits”，这会初始化JournalNode中的数据。</span>
<span class="gp">$ </span>sbin/hadoop-daemon.sh start journalnode

<span class="c">#2.2 格式化nimbusz节点的namenode，并启动查看web页面是否为standby状态</span>
<span class="gp">$ </span>bin/hdfs namenode -format
<span class="gp">$ </span>sbin/hadoop-daemon.sh start namenode
<span class="gp">$ </span>curl http://nimbusz:50070

<span class="c">#2.3 在supervisor01z节点同步nimbusz节点的namenode的状态，并启动supervisor01z的namenode节点</span>
<span class="gp">$ </span>bin/hdfs namenode -help
<span class="gp">$ </span>bin/hdfs namenode -bootstrapStandby
<span class="gp">$ </span>sbin/hadoop-daemon.sh start namenode

<span class="c">#2.4 分别启动3个datanode</span>
<span class="gp">$ </span>sbin/hadoop-daemon.sh start datanode

<span class="c">#2.5 到目前为止，两个nimbusz和supervisor01z这两个namenode都是standby待命状态的namenode，需要</span>
<span class="c">#使用haadmin命令将其中一个设置为active工作状态(这里将nimbusz设置active状态)</span>
<span class="gp">$ </span>bin/hdfs haadmin -transitionToActive nn1


<span class="c">#3.1 测试，创建文件夹，上传文件，读取文件</span>
<span class="gp">$ </span>bin/hdfs dfs -mkdir -p /user/ubuntu/wc/input
<span class="gp">$ </span>bin/hdfs dfs -put /opt/datas/wc.txt /user/ubuntu/wc/input
<span class="gp">$ </span>bin/hdfs dfs -text /opt/datas/wc.txt /user/ubuntu/wc/input/wc.txt

<span class="c">#3.2 现在将nimbusz节点的namenode杀掉(假设pid为18477，模拟namenode宕机)，</span>
<span class="c"># 手动切换supervisor01z的namenode为active状态，看namenode的HA是否生效</span>
<span class="gp">$ </span><span class="nb">kill</span> -9 18477 										  <span class="c">#在nimbusz节点操作</span>
<span class="gp">$ </span>bin/hdfs haadmin -transitionToActive nn2 --forceactive  <span class="c">#在supervisor01z节点操作</span>
<span class="gp">$ </span>bin/hdfs dfs -text /opt/datas/wc.txt /user/ubuntu/wc/input/wc.txt
</code></pre>
</div>

<blockquote>
  <p>注：这里也可以使用hadoop提供的快捷情动和关闭命令</p>

  <p>$ sbin/start-dfs.sh     #分别在对应的机器上启动namenode、datanode、journalnode</p>

  <p>$ sbin/stop-dfs.sh     #分别在对应的机器上关闭namenode、datanode、journalnode</p>
</blockquote>

<p><br /></p>

<h3 id="hdfs-ha-自动故障转移---zkfczk故障转移监听器">HDFS HA 自动故障转移 - ZKFC（ZK故障转移监听器）</h3>

<p>上述我们配置的 HDFS HA，当active的namenode发生故障宕机时，我们需要手动将另外的namenode切换为namenode工作节点。那么hadoop有没有提供一种机制，当namenode发生故障的时候，自动切换工作namenode呢？这就要用到 HDFS的 ZKFC机制。下面是 HDFS HA 集群自动故障转移的配置：<a href="http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">参考</a></p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c">#0.0 HDFS HA-ZKFC 集群的规划：</span>
nimbusz             supervisor01z           supervisor02z
---------------------------------------------------------
journalnode         journalnode             journalnode
namenode（active）   namenode（standby）						
datanode            datanode                datanode
zk                  zk                      zk


<span class="c">#1.1 hdfs-site.xml</span>
<span class="c">#增加如下配置参数</span>
&lt;property&gt;
	&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
   	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
   	&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
   	&lt;value&gt;nimbusz:2181,supervisor01z:2181,supervisor02z:2181&lt;/value&gt;
&lt;/property&gt;


<span class="c">#2.1 启动zk集群(分别在各个zk节点上启动zk服务)</span>
<span class="gp">$ </span>bin/zkService.sh start

<span class="c">#2.2 在zk数据树节点上根部生成 hadoop-ha/ns1/[nn1,nn2] 节点</span>
<span class="gp">$ </span>bin/hdfs zkfc -formatZK

<span class="c">#2.2 在nimbusz节点上启动 hdfs ha 集群，通过jps我们看到，hadoop会为每个namenode节点设置zkfc监控进程</span>
<span class="c"># 如果需要单独启动zkfc，则可以使用 sbin/hadoop.sh start zkfc 命令</span>
<span class="gp">$ </span>sbin/start-dfs.sh
<span class="gp">$ </span>jps <span class="c">#nimbusz节点</span>
23521 DataNode
23730 JournalNode
24040 Jps
23917 DFSZKFailoverController
18159 QuorumPeerMain
23375 NameNode

<span class="gp">$ </span>jps <span class="c">#supervisor01z节点</span>
24288 DataNode
24400 JournalNode
19537 QuorumPeerMain
24171 NameNode
24636 Jps
24527 DFSZKFailoverController

<span class="gp">$ </span>jps <span class="c">#supervisor02z节点</span>
21298 Jps
21203 JournalNode
21084 DataNode
18750 QuorumPeerMain


<span class="c">#3 测试 HDFS HA-ZKFC 集群是否能够完成故障的自动转移</span>
<span class="gp">$ </span>bin/hdfs dfs -put /opt/datas/test.txt /user/ubuntu/wc/input
<span class="gp">$ </span><span class="nb">kill</span> -9 23375  					<span class="c">#kill namenode in nimbusz</span>
<span class="gp">$ </span>curl http://supervisor01z:50070 	<span class="c">#check supervisor01z namenode if it's to active normal</span>
</code></pre>
</div>

<p>自动切换的流程：</p>

<ol>
  <li>zkfc通过rpc请求获取namenode状态</li>
  <li>zkfc连接zk完成选举，保持心跳</li>
  <li>另一台zkfc监控本机的namenode状态</li>
  <li>由于某种因素，对外提供服务的namenode出现异常宕机</li>
  <li>zkfc会在下一个监听的周期中检测到namenode失效的信息（zk的临时节点机制），触发后续的故障处理操作</li>
  <li>zkfc将失效的信息给到zk，zk会与另一台的节点进行通信，standby节点zkfc进入切换的流程</li>
  <li>zkfc首先将失效的namenode隔离出集群之外</li>
  <li>zkfc接下来进行选举，确认一个standby节点作为一个新的active节点</li>
  <li>zkfc完成选举之后，standby节点就切换成了active状态，接管HDFS集群的namenode工作</li>
</ol>

<p><br /></p>

<h3 id="resourcemanager-ha-架构">ResourceManager HA 架构</h3>

<p>hdfs在没有ha设置之前，namenode存在单点故障，而同样的 yarn resourcemanager 也会存在这样的问题。同样可以结合使用 zk 搭建 resourcemanager ha 的架构，来解决单点故障的问题，更进一步可以完成 resourcemanager的自动故障转移。下面是 resourcemanager ha zkfc 架构的搭建过程：</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c">#0.0 RsourceManager HA-ZKFC 集群的规划：</span>
nimbusz             supervisor01z            supervisor02z
--------------------------------------------------------------------
                    resourcemanager<span class="o">(</span>active<span class="o">)</span>  resourcemanager<span class="o">(</span>standby<span class="o">)</span>
nodemanager         nodemanager              nodemanager
zk                  zk                       zk


<span class="c">#1.1 yarn-site.xml </span>
&lt;configuration&gt;
    &lt;property&gt;
        &lt;!--代表是否开启resourcemanager的高可用功能--&gt;
        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--给resourcemanager集群指定一个id--&gt;
        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
        &lt;value&gt;rs1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--给resourcemanager两个节点指定的编号--&gt;
        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
        &lt;value&gt;rm1,rm2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--指定节点1的主机--&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;
        &lt;value&gt;supervisor01z&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--指定节点2的主机--&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;
        &lt;value&gt;supervisor02z&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--指定zk集群的节点--&gt;
        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
        &lt;value&gt;nimbusz:2181,supervisor01z:2181,supervisor02z:2181&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--当机器出现故障时候，任务是否重新提交执行--&gt;
        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;!--指定resourcemanager的状态信息存储在zk上（默认是存在文件系统上的）--&gt;
        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.
        		recovery.ZKRMStateStore&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
        &lt;value&gt;604800&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;


<span class="c">#2.1 启动zk集群(分别在各个zk节点上启动zk服务)</span>
<span class="gp">$ </span>bin/zkService.sh start

<span class="c">#2.2 在supervisor01z节点上启动 resourcemanager ha-zkfc 集群</span>
<span class="gp">$ </span>sbin/start-yarn.sh

<span class="c">#2.3 由于之前我们已经格式化过namenode，所以这里我们直接启动hdfs ha-zkfc集群</span>
<span class="gp">$ </span>sbin/start-dfs.sh 
<span class="gp">$ </span>hadoop-2.5.0/sbin/yarn-daemon.sh start resourcemanager

<span class="c">#2.4 观察各个节点上的服务状态</span>
<span class="gp">$ </span>jps 	<span class="c">#nimbusz</span>
11252 Jps
10344 NodeManager
10648 NameNode
9753 QuorumPeerMain
10793 DataNode
11001 JournalNode
11194 DFSZKFailoverController

<span class="gp">$ </span>jps	<span class="c">#supervisor01z</span>
11376 JournalNode
10673 NodeManager
11508 DFSZKFailoverController
9672 QuorumPeerMain
11626 Jps
10522 ResourceManager
11148 NameNode
11263 DataNode

<span class="gp">$ </span>jps	<span class="c">#supervisor02z</span>
10432 DataNode
10544 JournalNode
10644 Jps
10262 ResourceManager
10088 NodeManager
9593 QuorumPeerMain


<span class="c">#2.4 测试MR任务执行的过程中，认为模拟supervisor01z的resourcemanager宕机，观察任务是否正常执行完成</span>
<span class="c"># 如果任务重启并执行完成，说明 resourcemanager ha-zkfc环境搭建成功。</span>
<span class="gp">$ </span>bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /user/ubuntu/wc/input /user/ubuntu/wc/output
<span class="gp">$ </span><span class="nb">kill</span> -9 10522

<span class="c">#在上述测试的测试的过程中，我们观察到有下面的一句话输出，说明resourcemanager ha-zkfc环境搭建成功：</span>
<span class="c">#17/08/10 19:50:08 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm2</span>
</code></pre>
</div>

<p><br /></p>


                    <hr>
                    <div class="row">
                        <div class="col-md-6">
                                <h5 style="display: inline;">Tags:</h5>
                                
                                    <button class="btn btn-white btn-xs" type="button">java</button>
                                
                        </div>
                        
                        <!--
                        <div class="col-md-6">
                            <div class="small text-right">
                                <div>    
                                    <i class="fa fa-comments-o"> </i> 
                                    <span class="ds-comments">0</span>条评论
                                </div>
                                <div>
                                    <i class="fa fa-share-alt"> </i> 
                                    <span class="ds-shares">0</span>条转发
                                </div>  
                            </div>
                        </div>
                        -->
                    </div>
                    <br>
                    <div class="row">
                        <div class="col-lg-12">
                            <!-- donate -->
                            
                                <button type="button" class="btn btn-primary" data-toggle="modal" data-target="#myModal2">
    Donate
</button>
<div class="modal inmodal" id="myModal2" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content animated flipInY">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title">Donate Me</h4>
                <small class="font-bold">Thanks for your support!</small>
            </div>
            <div class="modal-body">
                <div class="tabbable" id="tabs-960227">
                    <ul class="nav nav-tabs">
                        <li class="active">
                            <a href="#panel-405278" data-toggle="tab">Alipay</a>
                        </li>
                        <li>
                            <a href="#panel-874705" data-toggle="tab">Wechat</a>
                        </li>
                    </ul>
                    <div class="tab-content">
                        <div class="tab-pane active" id="panel-405278">
                            <div class="text-center">
                                <img src="/static/img/pay/alipay.png"" height="250" width="250">
                            </div>    
                        </div>
                        <div class="tab-pane" id="panel-874705">
                            <div class="text-center">
                                <img src="/static/img/pay/wechat.png"" height="250" width="250">
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-white" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

                            
                            <br>
                            <!-- share -->
                            
                                
<!--分享-->
<div class="row" style="margin-top:30px;">
	<h2>Share:</h2>
    <div class="social-share" style="margin-left:-5px;"data-sites="wechat,qq,qzone,weibo"></div> 
</div>
<link rel="stylesheet" href="/static/css/share.min.css">
<script src="/static/js/jquery.share.min.js"></script>
<script src="/static/js/embed.js"></script>

<script>
  var url = 'http://localhost:4000/java/2017/08/08/java-hadoop-03.html';
  var source = 'http://localhost:4000/java/2017/08/08/java-hadoop-03.html';
  var title = 'hadoop完全分布式环境的搭建以及HDFS和YARN的HA配置（三）';
  var excerpt = $("p:eq(0)").text();
  
  var imageUrl = 'http://localhost:4000/static/img/landing/header_one.jpg';
  var imgEle = $(".content_img:eq(0)");
  if (imgEle) {
    imageUrl = imgEle.attr("src");
  }

  var $config = {
      url: url, // 网址，默认使用 window.location.href
      source: source, // 来源（QQ空间会用到）, 默认读取head标签：<meta name="site" content="http://overtrue" />
      title: title, // 标题，默认读取 document.title 或者 <meta name="title" content="share.js" />
      description: excerpt, // 描述, 默认读取head标签：<meta name="description" content="PHP弱类型的实现原理分析" />
      image: imageUrl, // 图片, 默认取网页中第一个img标签
      sites: ['qzone', 'qq', 'weibo','wechat','douban'], // 启用的站点
      //disabled: ['google', 'facebook', 'twitter'], // 禁用的站点
      wechatQrcodeTitle: "微信扫一扫：分享", // 微信二维码提示文字
      wechatQrcodeHelper: '<p style="font-size:10px;">微信里点“发现”，扫一下</p><p style="font-size:10px;">二维码便可将本文分享至朋友圈。</p>',
   };
  $('.social-share').share($config);
</script>




                            
                            <br>
                            <!-- comment -->
                            <!--



-->

<!-- 多说评论框 start -->
<div class="row" style="margin-top:25px;"></div>
<div class="ds-thread" data-thread-key="/java/2017/08/08/java-hadoop-03.html" data-title="hadoop完全分布式环境的搭建以及HDFS和YARN的HA配置（三）" data-url="http://localhost:4000/java/2017/08/08/java-hadoop-03.html"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
	var duoshuoQuery = {short_name:"kinglyjn"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
</script>
<!-- 多说公共JS代码 end -->



                        </div>
                    </div>

                </div>
            </div>
        </div>
    </div>

</div>



	
	    <script src="/static/js/scroll.js"></script>

<!-- Baidu analytics -->


<!-- Google analytics -->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-73784599-1', 'auto');
    ga('send', 'pageview');

  </script>


<!--

-->

<!--

-->

<script async src="/static/js/count_page.js"></script>

	

</body>
</html>