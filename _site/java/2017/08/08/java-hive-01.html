<!DOCTYPE html>
<html>
	
	    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <meta content="hive的基本简介及安装、配置、使用（一）" name="description">
  
  
    <meta name="keywords" content="hive的基本简介及安装、配置、使用（一）,hive,kinglyjn">
  
  <meta name="author" content="KinglyJn">

  <title>
    
        KinglyJn|hive的基本简介及安装、配置、使用（一）
    
  </title>
  <!-- favicon -->
  <link rel="shortcut icon" href="static/img/favicon.ico">


  <!-- Third-party CSS -->
  <link href="/bower_components/normalize-css/normalize.min.css" rel="stylesheet">
  <link href="/bower_components/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="/bower_components/animate.css/animate.min.css" rel="stylesheet">
  <link href="/bower_components/components-font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="/static/font-mfizz/font-mfizz.css" rel="stylesheet">
  <!-- <link href="/bower_components/toastr/toastr.min.css" rel="stylesheet"> -->
  <link href="/bower_components/jquery.gritter/css/jquery.gritter.css" rel="stylesheet">
  <link rel="stylesheet" href="/search/css/cb-search.css">

  <!-- Custom styles for this template -->
  <link href="/static/css/style.min.css" rel="stylesheet">
  <link href="/static/css/pygments.css" rel="stylesheet">

  <!-- Scripts -->
  <script src="/bower_components/jquery/dist/jquery.min.js"></script>
  <script src="/search/js/bootstrap3-typeahead.min.js"></script>

  <!-- cb-search -->
  <script src="/search/js/cb-search.js"></script>
  <script>
    $(function(){
        $("pre").css('display','block');
    });
  </script>
  <!-- Mainly scripts -->
  <script src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
  <script src="/bower_components/metisMenu/dist/metisMenu.min.js"></script>
  <script src="/bower_components/jquery-slimscroll/jquery.slimscroll.min.js"></script>

  <!-- Peity -->
  <script src="/bower_components/peity/jquery.peity.min.js"></script>

  <script src="/bower_components/PACE/pace.min.js"></script>
  <script src="/bower_components/wow/dist/wow.min.js"></script>
  <!-- Custom and plugin javascript -->
  <script src="/static/js/inspinia.js"></script>

  <!-- Rickshaw -->
  <script src="/bower_components/rickshaw/vendor/d3.v3.js"></script>
  <script src="/bower_components/rickshaw/rickshaw.min.js"></script>


  <!-- jPages -->
  <script src="/static/js/jPages.js"></script>
  <script src="/static/js/js.js"></script>
  <script type="text/javascript">
        $(function(){
          /* initiate the plugin */
          $("div.pag-holder").jPages({
              containerID  : "pag-itemContainer",
              perPage      : 10,  /* num of items per page */
              startPage    : 1,
              startRange   : 1,
              midRange     : 3,
              endRange     : 1
          });

          $("div.pag-jump button").click(function(){
            var page = parseInt($("div.pag-jump input").val());
            $("div.pag-holder").jPages(page);
          });

          $("div.pag-jump input").on("keypress", function(){
            var e=e||window.event;
            if (e.keyCode == 13) {
                var page = parseInt($("div.pag-jump input").val());
                $("div.pag-holder").jPages(page);
            } 
          });
      });
  </script>

<!-- GrowingIO -->

  <script>
    var _vds = _vds || [];
    window._vds = _vds;
    (function(){
      _vds.push(['setAccountId', 'a49d4901c7853da9']);
      (function() {
        var vds = document.createElement('script');
        vds.type='text/javascript';
        vds.async = true;
        vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(vds, s);
      })();
    })();
  </script>


</head>

	


<body id="page-top" class="landing-page">

	
	    

<!--修复手机端横轴方向左右滑动BUG-->
<style type="text/css">
    .landing-page .row {
        margin-left: 0px;
        margin-right: 0px;
    }
</style>

<div class="search-tool"
      style="position: fixed; top: 0px ; bottom: 0px; left: 0px; right:  0px; opacity: 0.95; background-color: #111111; z-index: 9999; display: none;">
    <input type="text" class="form-control search-content" id="search-content" style="position: fixed; top: 60px" placeholder="Search Blog">

    <div style="position: fixed; top: 16px; right: 16px; z-index: 9999;">
        <img src="/search/img/cb-close.png" id="close-btn"/>
    </div>
</div>

<div style="position: fixed; right: 16px; bottom: 20px; z-index: 9999;">
    <img src="/search/img/cb-search.png"  id="search-btn"  title="Double click Ctrl"/>
</div>

<div class="navbar-wrapper">
        <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">
                <div class="navbar-header page-scroll">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">KinglyJn</a>
                </div>
                <div id="navbar" class="navbar-collapse collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a class="page-scroll" href="/blog/"></a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/blog/">Blog</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/linux/">Linux</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/cloud/">Cloud</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/java/">Java</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/c/">C</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/php/">PHP</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/db/">DB</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/htmlx/">HTMLX</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/life/">Life</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/art/">Art</a></li>
                        
                            
                            <li>
                            
                            <a class="page-scroll" href="/other/">Other</a></li>
                        
                    </ul>
                </div>
            </div>
        </nav>
</div>
<div id="inSlider" class="carousel carousel-fade" data-ride="carousel">
    <div style="position:absolute;float:left;left:25%;z-index:15;width:50%;margin-bottom:18%;bottom:0;text-align:center;list-style:none;">
        <span style="color:white;font-size:24px;">以平实之心写作</span><br>
        <span style="color:white;font-size:13px;">writing with simple heart ♬. </span>
    </div>
    <!--
    <ol class="carousel-indicators">
        <li data-target="#inSlider" data-slide-to="0" class="active"></li>
        <li data-target="#inSlider" data-slide-to="1"></li>
    </ol>
    -->
    <div class="carousel-inner" role="listbox">
        <div class="item active">
            <div class="container">
                <div class="carousel-caption">
                </div>
                <div class="carousel-image wow zoomIn">
                    <!-- <img src="static/img/landing/laptop.png" alt="laptop"/> -->
                </div>
            </div>
            <!-- Set background for slide in css -->
            <div class="header-back blog-one"></div>
        </div>
        <!--
        <div class="item">
            <div class="container">
                <div class="carousel-caption blank">
                </div>
            </div>
            Set background for slide in css
            <div class="header-back two"></div>
        </div>
        -->
    </div>
    <!--
    <a class="left carousel-control" href="#inSlider" role="button" data-slide="prev">
        <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
    </a>
    <a class="right carousel-control" href="#inSlider" role="button" data-slide="next">
        <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
    </a>
    -->
</div>


	

    <div class="wrapper wrapper-content  animated fadeInRight article">
    <div class="row">
        <div class="col-lg-10 col-lg-offset-1">
            <div class="ibox">
                <div class="ibox-content">
                    <div class="pull-right">
                    	
                        	<button class="btn btn-white btn-xs" type="button">Java</button>
                        
                    </div>
                    <div class="text-center article-title" style="margin-bottom:50px;">
                        <h1>
                            hive的基本简介及安装、配置、使用（一）
                        </h1>
                        <a href="http://www.keyllo.com/studio/">
                            <span class="text-muted"><i class="fa fa-user"></i> KinglyJn</span>
                        </a>
                        &nbsp;&nbsp;&nbsp;&nbsp;
                        <span class="text-muted"><i class="fa fa-clock-o"></i> 2017-08-08</span>
                    </div>
                    	<blockquote>
  <p>hive是什么？</p>

  <ol>
    <li>由facebook开源，用于解决海量结构化日志的数据统计；</li>
    <li>基于hadoop的一个数据仓库工具，使用HDFS进行存储并将结构化数据文件映射成一张表，并提供类sql查询的功能，其底层采用MR进行计算；</li>
    <li>本质是将HQL转化成MR程序。</li>
  </ol>
</blockquote>

<p><br /></p>

<h3 id="hive架构图">hive架构图</h3>

<p><img src="http://img.blog.csdn.net/20170823183245175?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQva2luZ2x5am4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" style="width:70%" /></p>

<p><br /></p>

<h3 id="安装前的准备">安装前的准备</h3>

<ul>
  <li>Java 1.7 (preferred)</li>
  <li>Hadoop 2.x (preferred), 1.x (not supported by Hive 2.0.0 onward).</li>
</ul>

<p><br /></p>

<h3 id="简单安装hive以0131版本为例">简单安装HIVE（以0.13.1版本为例）</h3>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 1. 下载解压安装包</span>
wget http://archive.apache.org/dist/hive/hive-0.13.1/apache-hive-0.13.1-bin.tar.gz
tar -zxvf apache-hive-0.13.1-bin.tar.gz -C /opt/module

<span class="c"># 2. 配置文件</span>
<span class="c"># 2.1. conf/hive-env.sh</span>
cp hive-env.sh.template  hive-env.sh
vim hive-env.sh
	<span class="nv">HADOOP_HOME</span><span class="o">=</span>/opt/modules/hadoop-2.5.0
	<span class="nb">export </span><span class="nv">HIVE_CONF_DIR</span><span class="o">=</span>/opt/modules/apache-hive-0.13.1-bin/conf

<span class="c"># 3. 在HDFS上创建默认的存储路径(/tmp 和 /user/hive/warehouse，并且赋予权限chmod g+w)</span>
<span class="c"># 通过查找hive-default.xml.template可知，该值可以通过 hive.metastore.warehouse.dir 参数设置</span>
<span class="nv">$HADOOP_HOME</span>/bin/hadoop fs -mkdir       /tmp
<span class="nv">$HADOOP_HOME</span>/bin/hadoop fs -mkdir       /user/hive/warehouse
<span class="nv">$HADOOP_HOME</span>/bin/hadoop fs -chmod g+w   /tmp
<span class="nv">$HADOOP_HOME</span>/bin/hadoop fs -chmod g+w   /user/hive/warehouse

<span class="c"># 4. 启动hive的cli客户端，运行一个MR测试任务</span>
bin/hive
<span class="gp">&gt; </span>show databases;
<span class="gp">&gt; </span>use default;
<span class="gp">&gt; </span>show tables;
<span class="gp">&gt; </span>create table test_log<span class="o">(</span>ip string, user string, requrl string<span class="o">)</span>;
<span class="gp">&gt; </span>desc test_log;
<span class="gp">&gt; </span><span class="k">select </span>count<span class="o">(</span><span class="k">*</span><span class="o">)</span> from test_log;
</code></pre>
</div>

<p><br /></p>

<h3 id="使用mysql存储hive元数据">使用mysql存储hive元数据</h3>

<p>hive元数据默认是存放在derby内存数据库中的，也就是说一次只允许一个客户端操作，这时候如果有另一个客户端运行（bin/hive），则就会报如下错误：</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>Exception <span class="k">in </span>thread <span class="s2">"main"</span> java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient

Caused by: javax.jdo.JDOFatalDataStoreException: Unable to open a <span class="nb">test </span>connection to the given database. JDBC url <span class="o">=</span> jdbc:derby:;databaseName<span class="o">=</span>metastore_db;create<span class="o">=</span><span class="nb">true</span>, username <span class="o">=</span> APP. Terminating connection pool <span class="o">(</span><span class="nb">set </span>lazyInit to <span class="nb">true </span><span class="k">if </span>you expect to start your database after your app<span class="o">)</span>. Original Exception: ------
java.sql.SQLException: Failed to start database <span class="s1">'metastore_db'</span> with class loader sun.misc.Launcher<span class="nv">$AppClassLoader</span>@404b9385, see the next exception <span class="k">for </span>details.
</code></pre>
</div>

<p>在企业中通常推荐使用mysql存储hive的元数据，如下是hive与mysql的集成方法：</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 1. 拷贝mysql的驱动jar包到 hive的lib文件夹中</span>
cp mysql-connector-java-5.1.38.jar <span class="nv">$HIVE_HOME</span>/lib/

<span class="c"># 2. 新建一个 conf/hive-site.xml 文件用于配置 hive 的环境参数</span>
cp hive-default.xml.template hive-site.xml
vim hive-site.xml
---------------------
&lt;?xml <span class="nv">version</span><span class="o">=</span><span class="s2">"1.0"</span>?&gt;
&lt;?xml-stylesheet <span class="nb">type</span><span class="o">=</span><span class="s2">"text/xsl"</span> <span class="nv">href</span><span class="o">=</span><span class="s2">"configuration.xsl"</span>?&gt;
&lt;configuration&gt;
    &lt;!--hive metastore with mysql--&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
        &lt;value&gt;jdbc:mysql://dbserver:3306/hivemetastore?createDatabaseIfNotExist<span class="o">=</span><span class="nb">true</span>&lt;/value&gt;
        &lt;description&gt;JDBC connect string <span class="k">for </span>a JDBC metastore&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
        &lt;description&gt;Driver class name <span class="k">for </span>a JDBC metastore&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
        &lt;description&gt;username to use against metastore database&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
        &lt;value&gt;23wesdxc&lt;/value&gt;
        &lt;description&gt;password to use against metastore database&lt;/description&gt;
    &lt;/property&gt;

    &lt;!--cli header message--&gt;
    &lt;property&gt;
        &lt;name&gt;hive.cli.print.header&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;Whether to print the names of the columns <span class="k">in </span>query output.&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.cli.print.current.db&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;Whether to include the current database <span class="k">in </span>the Hive prompt.&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

<span class="c"># 3. 运行hive客户端之后会在mysql生成存储metastore数据的数据库（例如hivemetastore）</span>
bin/hive


<span class="c"># [注1]</span>
用mysql做元数据，需要在mysql命令行执行：
alter database hivemetastore character <span class="nb">set </span>latin1;
这样才不会报  max key length is 767 bytes 
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Specified key was too long; max key length is 767 bytes
这个异常

<span class="c"># [注2]</span>
在hive中,show tables,create 等命令能正常执行,删除表drop table x时,会出现卡住的现象.
进入mysql,
show variables like <span class="s1">'char%'</span>
可以看到，按理说是正确的.
后面发现,是在建好hive数据库后,没有第一时间将character_set_database编码由utf8修改为latin1.而是去hive中create了一张表.而后才将character_set_database编码由utf8改成了latin

解决办法:
在mysql中将drop hive
重新create hive,
修改编码,alter database hive character <span class="nb">set </span>latin1
进入hive shell
创建表,drop表,正常!
</code></pre>
</div>

<p><br /></p>

<h3 id="日志hive的简单配置">日志hive的简单配置</h3>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 1. 在模板的基础上新建 conf/hive-log4j.properties 文件（日志参数设置）</span>
cp hive-log4j.properties.template hive-log4j.properties

<span class="c"># 2.1 使用hive-log4j.properties日志参数配置</span>
bin/hive
Logging initialized using configuration <span class="k">in </span>file:/opt/modules/apache-hive-0.13.1-bin/conf/hive-log4j.properties

<span class="c"># 2.2 使用自定义日志参数配置</span>
<span class="gp">&gt; </span>bin/hive -help
usage: hive
 -d,--define &lt;<span class="nv">key</span><span class="o">=</span>value&gt;          Variable subsitution to apply to hive
                                  commands. e.g. -d <span class="nv">A</span><span class="o">=</span>B or --define <span class="nv">A</span><span class="o">=</span>B
    --database &lt;databasename&gt;     Specify the database to use
 -e &lt;quoted-query-string&gt;         SQL from <span class="nb">command </span>line
 -f &lt;filename&gt;                    SQL from files
 -h &lt;hostname&gt;                    connecting to Hive Server on remote host
 -H,--help                        Print <span class="nb">help </span>information
    --hiveconf &lt;<span class="nv">property</span><span class="o">=</span>value&gt;   Use value <span class="k">for </span>given property
    --hivevar &lt;<span class="nv">key</span><span class="o">=</span>value&gt;         Variable subsitution to apply to hive
                                  commands. e.g. --hivevar <span class="nv">A</span><span class="o">=</span>B
 -i &lt;filename&gt;                    Initialization SQL file
 -p &lt;port&gt;                        connecting to Hive Server on port number
 -S,--silent                      Silent mode <span class="k">in </span>interactive shell
 -v,--verbose                     Verbose mode <span class="o">(</span><span class="nb">echo </span>executed SQL to the
                                  console<span class="o">)</span>
                                  
<span class="gp">&gt; </span>bin/hive --hiveconf hive.root.logger<span class="o">=</span>INFO,console

<span class="c"># 2.3 日志文件的位置</span>
cat hive-log4j.properties
...
hive.log.dir<span class="o">=</span><span class="k">${</span><span class="nv">java</span><span class="p">.io.tmpdir</span><span class="k">}</span>/<span class="k">${</span><span class="nv">user</span><span class="p">.name</span><span class="k">}</span>  
hive.log.file<span class="o">=</span>hive.log <span class="c"># 即 /tmp/ubuntu/hive.log 文件</span>
...

hive/bin
<span class="gp">&gt; </span><span class="nb">set</span>
<span class="gp">&gt; </span><span class="nb">set </span>system:user.name; <span class="c">#当前会话查看</span>
<span class="gp">&gt; </span><span class="nb">set </span>system:user.name<span class="o">=</span>ubuntu; <span class="c">#当前会话设置</span>
...
system:java.io.tmpdir<span class="o">=</span>/tmp
system:user.name<span class="o">=</span>ubuntu
...
</code></pre>
</div>

<p><br /></p>

<h3 id="hive-cli常见交互命令">hive cli常见交互命令</h3>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># hive cli 帮助</span>
bin/hieve -help


<span class="c"># 查看hive的函数的相关命令：</span>
show functions;
desc <span class="k">function </span>upper;
desc <span class="k">function </span>extended upper;


<span class="c"># 在hive cli 交互窗口执行hdfs命令：</span>
hive <span class="o">(</span>default<span class="o">)</span>&gt; dfs -rm -R /user/ubuntu/xxx.log


<span class="c"># 在hive cli 交互窗口运行linux本地命令：</span>
hive <span class="o">(</span>default<span class="o">)</span>&gt; !ls /opt/datas


<span class="c"># 执行 hive sql 的五种方式：</span>
<span class="c"># 方式一：</span>
bin/hive -e <span class="s2">"select * from db_hive.student"</span>;
<span class="c"># 方式二：</span>
bin/hive -f xxx/xxx.sql
bin/hive -f xxx/xxx.sql &gt; xxx/result.txt
<span class="c"># 方式三：(UDF)</span>
bin/hive -i &lt;filename&gt; 
<span class="c"># 方式四：</span>
hive <span class="o">(</span>default<span class="o">)</span>&gt; <span class="nb">source </span>xxx/xxx.sql
<span class="c"># 方式五：</span>
hive <span class="o">(</span>default<span class="o">)</span>&gt; show databases;
hive <span class="o">(</span>default<span class="o">)</span>&gt; create database db_hive;
hive <span class="o">(</span>default<span class="o">)</span>&gt; use default;
hive <span class="o">(</span>default<span class="o">)</span>&gt; show tables;
</code></pre>
</div>

<p><br /></p>

<h3 id="hive-cli-ddldml">hive cli DDL/DML</h3>

<p>数据库相关：</p>

<div class="language-sql highlighter-rouge"><pre class="highlight"><code><span class="c1">-- 查看数据库(默认的数据库为default)</span>
<span class="k">show</span> <span class="n">databases</span><span class="p">;</span>
<span class="k">show</span> <span class="n">databases</span> <span class="k">like</span> <span class="nv">"db*"</span><span class="p">;</span>
<span class="k">desc</span> <span class="k">database</span> <span class="n">db_hive_01</span><span class="p">;</span>

<span class="c1">-- 创建和使用数据库</span>
<span class="k">CREATE</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="p">[</span><span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">database_name</span>
		  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">database_comment</span><span class="p">]</span>
		  <span class="p">[</span><span class="k">LOCATION</span> <span class="n">hdfs_path</span><span class="p">]</span>
		  <span class="p">[</span><span class="k">WITH</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...)];</span>

<span class="k">create</span> <span class="k">database</span> <span class="n">db_hive_01</span><span class="p">;</span>
<span class="k">create</span> <span class="k">database</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span><span class="p">;</span>
<span class="k">create</span> <span class="k">database</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span> <span class="k">comment</span> <span class="s1">'Hive数据库01'</span><span class="p">;</span>
<span class="k">create</span> <span class="k">database</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span> <span class="k">comment</span> <span class="s1">'Hive数据库01'</span> <span class="k">location</span> <span class="s1">'/user/ubuntu/hive/warehouse/db_hive_01.db'</span><span class="p">;</span>
<span class="n">use</span> <span class="n">db_hive_01</span><span class="p">;</span>


<span class="c1">-- 修改数据库</span>
<span class="k">ALTER</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="n">database_name</span> <span class="k">SET</span> <span class="k">OWNER</span> <span class="p">[</span><span class="k">USER</span><span class="o">|</span><span class="k">ROLE</span><span class="p">]</span> <span class="n">user_or_role</span><span class="p">;</span><span class="err">  </span> <span class="c1">-- (Note: Hive 0.13.0 and later; SCHEMA added in Hive 0.14.0)</span>

<span class="k">ALTER</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="n">database_name</span> <span class="k">SET</span> <span class="n">DBPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...);</span><span class="err">  </span> <span class="c1">-- (Note: SCHEMA added in Hive 0.14.0)</span>

<span class="k">ALTER</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="n">database_name</span> <span class="k">SET</span> <span class="k">LOCATION</span> <span class="n">hdfs_path</span><span class="p">;</span> <span class="c1">-- (Note: Hive 2.2.1, 2.4.0 and later)</span>


<span class="c1">-- 删除数据库</span>
<span class="k">DROP</span> <span class="p">(</span><span class="k">DATABASE</span><span class="o">|</span><span class="k">SCHEMA</span><span class="p">)</span> <span class="p">[</span><span class="n">IF</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="n">database_name</span> <span class="p">[</span><span class="k">RESTRICT</span><span class="o">|</span><span class="k">CASCADE</span><span class="p">];</span>
<span class="k">drop</span> <span class="k">database</span> <span class="n">if</span> <span class="k">exists</span> <span class="n">db_hive_01</span> <span class="k">cascade</span><span class="p">;</span> <span class="c1">--如果数据库中存在表和数据，则删除需要cascade关键字，这样数据库的目录及其子目录也将被删掉</span>

</code></pre>
</div>

<p><br /></p>

<p>表相关：</p>

<p><img src="http://img.blog.csdn.net/20170825110838317?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQva2luZ2x5am4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" style="width:100%" /></p>

<div class="language-sql highlighter-rouge"><pre class="highlight"><code><span class="c1">-- 创建表</span>
<span class="k">CREATE</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="p">]</span> <span class="p">[</span><span class="k">EXTERNAL</span><span class="p">]</span> <span class="k">TABLE</span> <span class="p">[</span><span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span> <span class="c1">-- (Note: TEMPORARY available in Hive 0.14.0 and later)</span>
  <span class="p">[(</span><span class="n">col_name</span> <span class="n">data_type</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">],</span> <span class="p">...</span> <span class="p">[</span><span class="n">constraint_specification</span><span class="p">])]</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">table_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name</span> <span class="n">data_type</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">],</span> <span class="p">...)]</span>
  <span class="p">[</span><span class="n">CLUSTERED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="n">col_name</span><span class="p">,</span> <span class="p">...)</span> <span class="p">[</span><span class="n">SORTED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name</span> <span class="p">[</span><span class="k">ASC</span><span class="o">|</span><span class="k">DESC</span><span class="p">],</span> <span class="p">...)]</span> <span class="k">INTO</span> <span class="n">num_buckets</span> <span class="n">BUCKETS</span><span class="p">]</span>
  <span class="p">[</span><span class="n">SKEWED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="n">col_name</span><span class="p">,</span> <span class="p">...)</span>  <span class="c1">-- (Note: Available in Hive 0.10.0 and later)]</span>
     <span class="k">ON</span> <span class="p">((</span><span class="n">col_value</span><span class="p">,</span> <span class="n">col_value</span><span class="p">,</span> <span class="p">...),</span> <span class="p">(</span><span class="n">col_value</span><span class="p">,</span> <span class="n">col_value</span><span class="p">,</span> <span class="p">...),</span> <span class="p">...)</span>
     <span class="p">[</span><span class="n">STORED</span> <span class="k">AS</span> <span class="n">DIRECTORIES</span><span class="p">]</span>
  <span class="p">[</span>
   <span class="p">[</span><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">row_format</span><span class="p">]</span> 
   <span class="p">[</span><span class="n">STORED</span> <span class="k">AS</span> <span class="n">file_format</span><span class="p">]</span>
     <span class="o">|</span> <span class="n">STORED</span> <span class="k">BY</span> <span class="s1">'storage.handler.class.name'</span> <span class="p">[</span><span class="k">WITH</span> <span class="n">SERDEPROPERTIES</span> <span class="p">(...)]</span>  <span class="c1">-- (Note: Available in Hive 0.6.0 and later)</span>
  <span class="p">]</span>
  <span class="p">[</span><span class="k">LOCATION</span> <span class="n">hdfs_path</span><span class="p">]</span>
  <span class="p">[</span><span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...)]</span>   <span class="c1">-- (Note: Available in Hive 0.6.0 and later)</span>
  <span class="p">[</span><span class="k">AS</span> <span class="n">select_statement</span><span class="p">];</span>  <span class="c1">-- (Note: Available in Hive 0.5.0 and later; not supported for external tables)</span>
 
<span class="k">CREATE</span> <span class="p">[</span><span class="k">TEMPORARY</span><span class="p">]</span> <span class="p">[</span><span class="k">EXTERNAL</span><span class="p">]</span> <span class="k">TABLE</span> <span class="p">[</span><span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span>
  <span class="k">LIKE</span> <span class="n">existing_table_or_view_name</span>
  <span class="p">[</span><span class="k">LOCATION</span> <span class="n">hdfs_path</span><span class="p">];</span>
 
<span class="n">data_type</span>
  <span class="p">:</span> <span class="n">primitive_type</span>
  <span class="o">|</span> <span class="n">array_type</span>
  <span class="o">|</span> <span class="n">map_type</span>
  <span class="o">|</span> <span class="n">struct_type</span>
  <span class="o">|</span> <span class="n">union_type</span>  <span class="c1">-- (Note: Available in Hive 0.7.0 and later)</span>
 
<span class="n">primitive_type</span>
  <span class="p">:</span> <span class="n">TINYINT</span>
  <span class="o">|</span> <span class="n">SMALLINT</span>
  <span class="o">|</span> <span class="n">INT</span>
  <span class="o">|</span> <span class="n">BIGINT</span>
  <span class="o">|</span> <span class="n">BOOLEAN</span>
  <span class="o">|</span> <span class="n">FLOAT</span>
  <span class="o">|</span> <span class="n">DOUBLE</span>
  <span class="o">|</span> <span class="n">DOUBLE</span> <span class="k">PRECISION</span> <span class="c1">-- (Note: Available in Hive 2.2.0 and later)</span>
  <span class="o">|</span> <span class="n">STRING</span>
  <span class="o">|</span> <span class="n">BINARY</span>      <span class="c1">-- (Note: Available in Hive 0.8.0 and later)</span>
  <span class="o">|</span> <span class="k">TIMESTAMP</span>   <span class="c1">-- (Note: Available in Hive 0.8.0 and later)</span>
  <span class="o">|</span> <span class="n">DECIMAL</span>     <span class="c1">-- (Note: Available in Hive 0.11.0 and later)</span>
  <span class="o">|</span> <span class="n">DECIMAL</span><span class="p">(</span><span class="k">precision</span><span class="p">,</span> <span class="k">scale</span><span class="p">)</span>  <span class="c1">-- (Note: Available in Hive 0.13.0 and later)</span>
  <span class="o">|</span> <span class="n">DATE</span>        <span class="c1">-- (Note: Available in Hive 0.12.0 and later)</span>
  <span class="o">|</span> <span class="n">VARCHAR</span>     <span class="c1">-- (Note: Available in Hive 0.12.0 and later)</span>
  <span class="o">|</span> <span class="n">CHAR</span>        <span class="c1">-- (Note: Available in Hive 0.13.0 and later)</span>
 
<span class="n">array_type</span>
  <span class="p">:</span> <span class="n">ARRAY</span> <span class="o">&lt;</span> <span class="n">data_type</span> <span class="o">&gt;</span>
 
<span class="n">map_type</span>
  <span class="p">:</span> <span class="k">MAP</span> <span class="o">&lt;</span> <span class="n">primitive_type</span><span class="p">,</span> <span class="n">data_type</span> <span class="o">&gt;</span>
 
<span class="n">struct_type</span>
  <span class="p">:</span> <span class="n">STRUCT</span> <span class="o">&lt;</span> <span class="n">col_name</span> <span class="p">:</span> <span class="n">data_type</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment</span><span class="p">],</span> <span class="p">...</span><span class="o">&gt;</span>
 
<span class="n">union_type</span>
   <span class="p">:</span> <span class="n">UNIONTYPE</span> <span class="o">&lt;</span> <span class="n">data_type</span><span class="p">,</span> <span class="n">data_type</span><span class="p">,</span> <span class="p">...</span> <span class="o">&gt;</span>  <span class="c1">-- (Note: Available in Hive 0.7.0 and later)</span>
 
<span class="n">row_format</span>
  <span class="p">:</span> <span class="n">DELIMITED</span> <span class="p">[</span><span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="n">char</span> <span class="p">[</span><span class="n">ESCAPED</span> <span class="k">BY</span> <span class="n">char</span><span class="p">]]</span> <span class="p">[</span><span class="n">COLLECTION</span> <span class="n">ITEMS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="n">char</span><span class="p">]</span>
        <span class="p">[</span><span class="k">MAP</span> <span class="n">KEYS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="n">char</span><span class="p">]</span> <span class="p">[</span><span class="n">LINES</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="n">char</span><span class="p">]</span>
        <span class="p">[</span><span class="k">NULL</span> <span class="k">DEFINED</span> <span class="k">AS</span> <span class="n">char</span><span class="p">]</span>   <span class="c1">-- (Note: Available in Hive 0.13 and later)</span>
  <span class="o">|</span> <span class="n">SERDE</span> <span class="n">serde_name</span> <span class="p">[</span><span class="k">WITH</span> <span class="n">SERDEPROPERTIES</span> <span class="p">(</span><span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="n">property_name</span><span class="o">=</span><span class="n">property_value</span><span class="p">,</span> <span class="p">...)]</span>
 
<span class="n">file_format</span><span class="p">:</span>
  <span class="p">:</span> <span class="n">SEQUENCEFILE</span>
  <span class="o">|</span> <span class="n">TEXTFILE</span>    <span class="c1">-- (Default, depending on hive.default.fileformat configuration)</span>
  <span class="o">|</span> <span class="n">RCFILE</span>      <span class="c1">-- (Note: Available in Hive 0.6.0 and later)</span>
  <span class="o">|</span> <span class="n">ORC</span>         <span class="c1">-- (Note: Available in Hive 0.11.0 and later)</span>
  <span class="o">|</span> <span class="n">PARQUET</span>     <span class="c1">-- (Note: Available in Hive 0.13.0 and later)</span>
  <span class="o">|</span> <span class="n">AVRO</span>        <span class="c1">-- (Note: Available in Hive 0.14.0 and later)</span>
  <span class="o">|</span> <span class="n">INPUTFORMAT</span> <span class="n">input_format_classname</span> <span class="n">OUTPUTFORMAT</span> <span class="n">output_format_classname</span>
 
<span class="n">constraint_specification</span><span class="p">:</span>
  <span class="p">:</span> <span class="p">[,</span> <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="p">...)</span> <span class="n">DISABLE</span> <span class="n">NOVALIDATE</span> <span class="p">]</span>
    <span class="p">[,</span> <span class="k">CONSTRAINT</span> <span class="k">constraint_name</span> <span class="k">FOREIGN</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="p">...)</span> <span class="k">REFERENCES</span> <span class="k">table_name</span><span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="p">...)</span> <span class="n">DISABLE</span> <span class="n">NOVALIDATE</span>
     

     
<span class="c1">-- 创建普通表示例(用location来指定数据文件的位置，这样创建表的时候也加载了数据)</span>
<span class="k">create</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive</span><span class="p">.</span><span class="n">student</span><span class="p">(</span>
  <span class="n">id</span> <span class="n">int</span> <span class="k">comment</span> <span class="s1">'学生id'</span><span class="p">,</span> 
  <span class="n">name</span> <span class="n">string</span> <span class="k">comment</span> <span class="s1">'学生姓名'</span>
<span class="p">)</span> <span class="k">comment</span> <span class="s1">'学生表'</span>
<span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> 
	<span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
    <span class="n">COLLECTION</span> <span class="n">ITEMS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span>
	<span class="n">STORED</span> <span class="k">AS</span> <span class="n">TEXTFILE</span>
    <span class="k">LOCATION</span> <span class="s1">'/user/ubuntu/hive/warehouse/student'</span><span class="p">;</span> 

<span class="c1">-- 创建一个外部表示例(企业中大部分应用场景下使用外部表，创建外部表时必须要指定location参数)</span>
<span class="k">create</span> <span class="k">external</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive</span><span class="p">.</span><span class="n">student</span><span class="p">(</span>
  <span class="n">id</span> <span class="n">int</span> <span class="k">comment</span> <span class="s1">'学生id'</span><span class="p">,</span> 
  <span class="n">name</span> <span class="n">string</span> <span class="k">comment</span> <span class="s1">'学生姓名'</span>
<span class="p">)</span> <span class="k">comment</span> <span class="s1">'学生表'</span>
<span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span> 
	<span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
    <span class="n">COLLECTION</span> <span class="n">ITEMS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span>
	<span class="n">STORED</span> <span class="k">AS</span> <span class="n">TEXTFILE</span>
    <span class="k">LOCATION</span> <span class="s1">'/user/ubuntu/datas/student'</span><span class="p">;</span>

<span class="c1">-- 普通表与外部表(external table)的区别：</span>
<span class="mi">1</span><span class="err">）创建表时：创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。</span>
<span class="mi">2</span><span class="err">）删除表时：在删除表的时候，内部表的元数据和数据会被一起删除，</span> <span class="err">而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。</span> 
<span class="mi">3</span><span class="err">）对于</span><span class="n">n</span><span class="err">个外部表指向</span><span class="n">HDFS</span><span class="err">同一个数据文件夹，当更改这个文件夹中的数据时，这</span><span class="n">n</span><span class="err">个外部表都会受到影响。</span> 
    
     

<span class="c1">-- 分区表</span>
<span class="err">分区表实际上就是对应一个</span><span class="n">hdfs</span><span class="err">文件系统上的一个独立的文件夹，该文件夹下是该分区所有的数据文件。</span><span class="n">hive</span><span class="err">中的分区就是分目录，把一个大的数据集根据业务的需要划分成更小的数据集。在查询时通过</span><span class="k">where</span><span class="err">子句中的表达式来选择查询所需要的指定的分区，这样的查询效率会体改很多。</span>
<span class="err">分区表的注意事项：对于普通表，先上传</span><span class="p">(</span><span class="n">hdfs</span> <span class="n">put</span><span class="p">)</span><span class="err">表相关数据文件到</span><span class="n">HDFS</span><span class="err">相对应的文件目录再创建表的方式</span> <span class="err">与</span> <span class="err">先创建表再加载</span><span class="p">(</span><span class="n">hive</span> <span class="k">load</span><span class="p">)</span><span class="err">表相关的数据文件到</span><span class="n">HDFS</span> <span class="err">这两种方式的效果是相同的；对于分区表，先上传</span><span class="p">(</span><span class="n">hdfs</span> <span class="n">put</span><span class="p">)</span><span class="err">表相关数据文件到</span><span class="n">HDFS</span><span class="err">相对应的文件目录再创建表之后，</span><span class="k">select</span><span class="err">查询该表格，结果是查不到刚才上传的数据的，因为分区表除了在</span><span class="n">mysql</span><span class="err">数据库存放与普通表相同的信息，还在</span><span class="n">mysql</span><span class="err">存储分区的相关信息（可以查询</span><span class="n">mysql</span><span class="o">-</span><span class="n">metastore</span><span class="err">：</span><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">patitions</span><span class="err">），这时候</span><span class="n">HIVE</span><span class="err">端分区表需要采取修复的方法，以在</span><span class="n">mysql</span><span class="err">端增加新创建分区表的</span><span class="n">metastore</span><span class="o">-</span><span class="n">patition</span><span class="err">信息。</span>
<span class="err">修复方法一：（一次性修复，</span><span class="n">msck</span><span class="err">：</span><span class="n">metastore</span> <span class="k">check</span><span class="err">）</span>
<span class="n">msck</span> <span class="n">repair</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_patition</span><span class="p">;</span>
<span class="err">修复方法二：（企业中常用）</span>
<span class="k">alter</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span> <span class="k">add</span> <span class="n">patition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'20170204'</span><span class="p">,</span><span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">);</span>

     
     
<span class="c1">-- 创建分区表</span>
<span class="c1">-- 先创建分区表，后向分区表中加载数据</span>
<span class="k">create</span> <span class="k">external</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">dept</span><span class="p">(</span><span class="n">deptno</span> <span class="n">int</span><span class="p">,</span> <span class="n">dname</span> <span class="n">string</span><span class="p">,</span> <span class="n">loc</span> <span class="n">string</span><span class="p">)</span>
<span class="n">partitioned</span> <span class="k">by</span><span class="p">(</span><span class="k">month</span> <span class="n">string</span><span class="p">,</span> <span class="k">day</span> <span class="n">string</span><span class="p">)</span> <span class="c1">--拥有两级分区</span>
<span class="k">row</span> <span class="n">format</span> <span class="n">delimited</span> <span class="n">fields</span> <span class="n">terminated</span> <span class="k">by</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
<span class="k">location</span> <span class="s1">'/user/ubuntu/datas/dept'</span><span class="p">;</span>
     
<span class="k">load</span> <span class="k">data</span> <span class="k">local</span> <span class="n">inpath</span> <span class="s1">'/opt/datas/dept01.txt'</span> <span class="k">into</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span> <span class="n">partition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201708'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">);</span>
<span class="k">load</span> <span class="k">data</span> <span class="k">local</span> <span class="n">inpath</span> <span class="s1">'/opt/datas/dept02.txt'</span> <span class="k">into</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span> <span class="n">partition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201708'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'02'</span><span class="p">);</span>     

<span class="c1">-- 先存存在数据文件，后创建分区表</span>
<span class="k">create</span> <span class="k">external</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">dept</span><span class="p">(</span><span class="n">deptno</span> <span class="n">int</span><span class="p">,</span> <span class="n">dname</span> <span class="n">string</span><span class="p">,</span> <span class="n">loc</span> <span class="n">string</span><span class="p">)</span>
<span class="n">partitioned</span> <span class="k">by</span><span class="p">(</span><span class="k">month</span> <span class="n">string</span><span class="p">,</span> <span class="k">day</span> <span class="n">string</span><span class="p">)</span> <span class="c1">--拥有两级分区</span>
<span class="k">row</span> <span class="n">format</span> <span class="n">delimited</span> <span class="n">fields</span> <span class="n">terminated</span> <span class="k">by</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
<span class="k">location</span> <span class="s1">'/user/ubuntu/datas/dept'</span><span class="p">;</span>
     
<span class="k">alter</span> <span class="k">table</span> <span class="n">dept</span> <span class="k">add</span> <span class="n">partition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201708'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">);</span>
<span class="k">alter</span> <span class="k">table</span> <span class="n">dept</span> <span class="k">add</span> <span class="n">partition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201708'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'02'</span><span class="p">);</span>
<span class="err">或</span>
<span class="n">msck</span> <span class="n">repair</span> <span class="k">table</span> <span class="nv">`db_hive_01.dept`</span><span class="p">;</span>
     
     
<span class="c1">-- 以as的方式创建表(CATS, create table as select)</span>
<span class="k">create</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">student_ctas</span>
<span class="k">as</span> <span class="k">select</span> <span class="n">id</span><span class="p">,</span><span class="n">name</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">student_01_ext</span><span class="p">;</span> <span class="c1">--会生成内部表的数据文件student_ctas/000000_0，包含了select查到的一些数据，删除内部表时也只删除内部表的数据文件</span>
     

<span class="c1">-- 以like的方式创建表(数据非常大，可以每天的数据放在新创建的一张表中)</span>
<span class="k">create</span> <span class="k">external</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="n">exsist</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">student_ext_03</span>
<span class="k">like</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">student_ext_02</span> <span class="k">location</span> <span class="s1">'/user/ubuntu/datas/student02'</span><span class="p">;</span>
 

     
<span class="c1">-- 查看表信息</span>
<span class="k">desc</span> <span class="n">db_hive</span><span class="p">.</span><span class="n">student</span><span class="p">;</span>
<span class="k">desc</span> <span class="n">extended</span> <span class="n">db_hive</span><span class="p">.</span><span class="n">student</span><span class="p">;</span>
<span class="k">desc</span> <span class="n">formatted</span> <span class="n">db_hive</span><span class="p">.</span><span class="n">student</span><span class="p">;</span>
     
     
<span class="c1">--查询某个分区的数据：</span>
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span> <span class="k">where</span> <span class="k">month</span><span class="o">=</span><span class="s1">'201708'</span><span class="p">;</span>
<span class="c1">-- 查看某张分区表的分区</span>
<span class="k">show</span> <span class="n">partitions</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span><span class="p">;</span>     
<span class="c1">-- 合并分区的数据：</span>
<span class="err">$</span><span class="n">vi</span> <span class="n">xxx</span><span class="p">.</span><span class="k">sql</span>
	<span class="k">select</span> <span class="n">dname</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span> <span class="k">where</span> <span class="k">month</span><span class="o">=</span><span class="s1">'201702'</span> <span class="k">and</span> <span class="k">day</span><span class="o">=</span><span class="s1">'01'</span>                 
	<span class="k">union</span> <span class="k">all</span>
	<span class="k">select</span> <span class="n">dname</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span> <span class="k">where</span> <span class="n">event_month</span><span class="o">=</span><span class="s1">'201703'</span> <span class="k">and</span> <span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">;</span>
<span class="err">$</span><span class="n">bin</span><span class="o">/</span><span class="n">hive</span> <span class="o">-</span><span class="n">f</span> <span class="n">xxx</span><span class="p">.</span><span class="k">sql</span> <span class="o">&gt;</span> <span class="n">xxx</span><span class="o">/</span><span class="k">result</span><span class="p">.</span><span class="n">txt</span><span class="p">;</span>


<span class="c1">-- 修改表名(如果是内部表，则相应的数据存储文件路径名也会被修改，注意修改的时候前面不能加数据库名)</span>
<span class="k">alter</span> <span class="k">table</span> <span class="n">student</span> <span class="k">rename</span> <span class="k">to</span> <span class="n">student01</span><span class="p">;</span>
     
     
<span class="c1">-- 清空表数据(只能清空内部表的数据)</span>
<span class="k">truncate</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">student</span><span class="p">;</span>
     
    
<span class="c1">-- group by聚合查询</span>
<span class="c1">-- 查询每个部门的平均工资示例：</span>
<span class="k">select</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span><span class="p">,</span> <span class="k">avg</span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">sal</span><span class="p">)</span> <span class="k">from</span> <span class="n">db_hibve_01</span><span class="p">.</span><span class="n">emp</span> <span class="n">e</span> <span class="k">group</span> <span class="k">by</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span><span class="p">;</span>  
<span class="c1">-- 查询每个部门中每个岗位的最高薪水示例：</span>
<span class="k">select</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span><span class="p">,</span><span class="n">e</span><span class="p">.</span><span class="n">job</span><span class="p">,</span><span class="k">max</span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">sal</span><span class="p">)</span> <span class="n">maxsal</span> <span class="k">from</span> <span class="n">db_hibve_01</span><span class="p">.</span><span class="n">emp</span> <span class="n">e</span> <span class="k">group</span> <span class="k">by</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span><span class="p">,</span><span class="n">e</span><span class="p">.</span><span class="n">job</span><span class="p">;</span>
     
     
<span class="c1">-- having过滤</span>
<span class="c1">-- having与where的区别：</span>
<span class="c1">-- where 是针对单条记录进行筛选，having 是针对分组的结果进行筛选</span>
<span class="c1">-- 求部门平均薪水大于2000的部门示例：</span>
<span class="k">select</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span><span class="p">,</span><span class="k">avg</span><span class="p">(</span><span class="n">sal</span><span class="p">)</span> <span class="n">avgsal</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">emp</span> <span class="n">e</span> <span class="k">group</span> <span class="k">by</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span> <span class="k">having</span> <span class="n">avgsal</span><span class="o">&gt;</span><span class="mi">2000</span><span class="p">;</span> 
     
     
<span class="c1">-- 多表查询join...on:</span>
<span class="k">select</span> <span class="n">e</span><span class="p">.</span><span class="n">empno</span><span class="p">,</span><span class="n">e</span><span class="p">.</span><span class="n">ename</span><span class="p">,</span><span class="n">d</span><span class="p">.</span><span class="n">deptno</span><span class="p">,</span><span class="n">d</span><span class="p">.</span><span class="n">dname</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">emp</span> <span class="n">e</span> <span class="k">join</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span> <span class="n">d</span> <span class="k">on</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span><span class="o">=</span><span class="n">d</span><span class="p">.</span><span class="n">deptno</span><span class="p">;</span>
     
 
     
<span class="c1">-- Hive对查询结果的排序</span>
<span class="c1">-- 1. order by，对全局数据的排序，只在一台节点运行，仅仅只有一个reduce，使用需谨慎！</span>
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">emp</span> <span class="k">order</span> <span class="k">by</span> <span class="n">empno</span><span class="p">;</span>

<span class="c1">-- 2. sort by，对每个reduce内部数据进行排序（即对每个分区的数据排序，默认的分区是hash-key对reduce个数取模，执行之前先设置reduce的个数），不是全局排序，对全局结果集来说是没有排序的</span>
<span class="k">set</span> <span class="n">mapreduce</span><span class="p">.</span><span class="n">job</span><span class="p">.</span><span class="n">reduces</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span> <span class="c1">--默认值为-1，一个reduce</span>
<span class="k">insert</span> <span class="n">overwrite</span> <span class="k">local</span> <span class="n">directory</span> <span class="s1">'/opt/datas/test/results/'</span> 
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">emp</span> <span class="n">sort</span> <span class="k">by</span> <span class="n">empno</span> <span class="k">asc</span><span class="p">;</span> <span class="c1">-- 会生成mapreduce.job.reduces个结果文件</span>
     
<span class="c1">-- 3. distribute by，设置MR分区，对数据进行分区，结合sort by使用</span>
<span class="c1">-- 注意：distribute by 必须要在sort by 之前！</span>
<span class="c1">-- 像下面的例子，一般有多少个部门编号(deptno)，就使用多少个reducer执行reduce任务(这样每个结果文件存储了一个分区的数据)</span>
<span class="k">insert</span> <span class="n">overwrite</span> <span class="k">local</span> <span class="n">directory</span> <span class="s1">'/opt/datas/test/results/'</span> 
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">emp</span> <span class="n">e</span> <span class="n">distribute</span> <span class="k">by</span> <span class="n">e</span><span class="p">.</span><span class="n">deptno</span> <span class="n">sort</span> <span class="k">by</span> <span class="n">e</span><span class="p">.</span><span class="n">empno</span><span class="p">;</span>
     
<span class="c1">-- 4. cluster by</span>
<span class="c1">-- 当distribute和sort字段相同时，使用该方式</span>
<span class="k">insert</span> <span class="n">overwrite</span> <span class="k">local</span> <span class="n">directory</span> <span class="s1">'/opt/datas/test/results/'</span> 
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span> <span class="n">d</span> <span class="k">cluster</span> <span class="k">by</span> <span class="n">d</span><span class="p">.</span><span class="n">deptno</span><span class="p">;</span>
</code></pre>
</div>

<p><br /></p>

<p>表数据的导入和导出：</p>

<div class="language-sql highlighter-rouge"><pre class="highlight"><code><span class="c1">-- hive导入源数据常见的九种形式：</span>
<span class="c1">-- 1. 加载本地文件到hive表：</span>
<span class="k">load</span> <span class="k">data</span> <span class="k">local</span> <span class="n">inpath</span> <span class="s1">'local_path'</span> <span class="k">into</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">;</span>

<span class="c1">-- 2. 加载dfs文件档hive表（加载完成后dfs文件会被删除）</span>
<span class="k">load</span> <span class="k">data</span> <span class="n">inpath</span> <span class="s1">'dfs_path'</span> <span class="k">into</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">;</span>

<span class="c1">-- 3. 覆盖表中已有的数据</span>
<span class="k">load</span> <span class="k">data</span> <span class="n">inpath</span> <span class="s1">'dfs_path'</span> <span class="n">overwrite</span> <span class="k">into</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">;</span>

<span class="c1">-- 4. 加载数据到分区表</span>
<span class="k">load</span> <span class="k">data</span> <span class="p">[</span><span class="k">local</span><span class="p">]</span> <span class="n">inpath</span> <span class="err">‘</span><span class="n">filepath</span><span class="err">’</span> <span class="p">[</span><span class="n">overwrite</span><span class="p">]</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span> <span class="n">partition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201708'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'02'</span><span class="p">,..);</span>

<span class="c1">-- 5. 创建表时通过select加载：</span>
<span class="k">create</span> <span class="p">[</span><span class="k">external</span><span class="p">]</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_ctas</span>
<span class="k">as</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">;</span>

<span class="c1">-- 6. 创建表时通过insert加载：</span>
<span class="k">create</span> <span class="p">[</span><span class="k">external</span><span class="p">]</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_like</span>
<span class="k">like</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="err">；</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_like</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">b_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">;</span>

<span class="c1">-- 7. 创建表时通过location指定加载：</span>
<span class="k">create</span> <span class="p">[</span><span class="k">external</span><span class="p">]</span> <span class="k">table</span> <span class="n">if</span> <span class="k">not</span> <span class="k">exists</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">(</span>
	<span class="n">deptno</span> <span class="n">int</span><span class="p">,</span>
	<span class="n">dname</span> <span class="n">string</span><span class="p">,</span>
	<span class="n">loc</span> <span class="n">string</span>
<span class="p">)</span> 
<span class="k">row</span> <span class="n">format</span> <span class="n">delimited</span> <span class="n">fields</span> <span class="n">terminated</span> <span class="k">by</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
<span class="k">location</span> <span class="s1">'pathxxx'</span><span class="p">;</span>

<span class="c1">-- 8. 修复表时加载：</span>
<span class="n">msck</span> <span class="n">repair</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_patition</span><span class="p">;</span>
<span class="n">alert</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span> <span class="k">add</span> <span class="n">patition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201702'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">);</span> 

<span class="c1">-- 9. import，将外部数据导入到hive表中去：</span>
<span class="n">import</span> <span class="p">[</span><span class="k">external</span><span class="p">]</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span> <span class="p">[</span><span class="n">patition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201702'</span><span class="p">,</span> <span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">)]</span> <span class="k">from</span> <span class="s1">'xxx/db_hive_01_dept_export'</span> <span class="p">[</span><span class="k">location</span> <span class="s1">'import_target_path'</span><span class="p">];</span>



<span class="c1">-- hive导出结果数据的四种常见的方式：</span>
<span class="c1">-- 1. 将结果数据插入到本地磁盘：</span>
<span class="n">hive</span><span class="p">(</span><span class="n">db_hive_01</span><span class="p">)</span><span class="o">&gt;</span> <span class="k">insert</span> <span class="p">[</span><span class="n">overwrite</span><span class="p">]</span> <span class="p">[</span><span class="k">local</span><span class="p">]</span> <span class="n">directory</span> <span class="s1">'filepath'</span>
							<span class="k">row</span> <span class="n">format</span> <span class="n">delimited</span>
								<span class="n">fields</span> <span class="n">terminated</span> <span class="k">by</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span>
								<span class="n">collection</span> <span class="n">items</span> <span class="n">terminited</span> <span class="k">by</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span>
							<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept</span><span class="p">;</span>

<span class="c1">-- 2. 直接在本地将执行结果重定向到指定文件</span>
<span class="n">bin</span><span class="o">/</span><span class="n">hive</span> <span class="o">-</span><span class="n">e</span> <span class="nv">"select * from db_hive_01.dept;"</span> <span class="o">&gt;</span> <span class="n">xxx</span><span class="o">/</span><span class="k">result</span><span class="p">.</span><span class="n">txt</span>

<span class="c1">-- 3. export方式将hive表中的数据导出到外部</span>
<span class="c1">-- 导出的路径是hdfs上的文件路径，导出操作会拷贝数据文件夹和文件到目标路径，而且会在目标路径下生成_metadata文件存储表的元数据信息</span>
<span class="n">export</span> <span class="k">table</span> <span class="n">db_hive_01</span><span class="p">.</span><span class="n">dept_partition</span> <span class="p">[</span><span class="n">partition</span><span class="p">(</span><span class="k">month</span><span class="o">=</span><span class="s1">'201702'</span><span class="p">,</span><span class="k">day</span><span class="o">=</span><span class="s1">'01'</span><span class="p">)]</span> <span class="k">to</span> <span class="s1">'distpath'</span><span class="p">;</span>

<span class="c1">-- 4. sqoop工具导入导出hive数据到传统关系数据库 或 Hbase</span>
<span class="err">略</span>
</code></pre>
</div>

<p><br /></p>

<p>其他hive命令:</p>

<div class="language-sql highlighter-rouge"><pre class="highlight"><code><span class="c1">-- hive交互窗口执行的命令历史记录位于</span>
<span class="o">~/</span><span class="p">.</span><span class="n">hivehistory</span>

<span class="c1">-- 查看函数</span>
<span class="k">show</span> <span class="n">functions</span><span class="p">;</span>
<span class="k">desc</span> <span class="k">function</span> <span class="k">upper</span><span class="p">;</span>
<span class="k">desc</span> <span class="k">function</span> <span class="n">extended</span> <span class="k">upper</span><span class="p">;</span>
</code></pre>
</div>

<p><br /></p>

<h3 id="hive的在etl中的应用">HIVE的在ETL中的应用</h3>

<pre><code class="language-default">1. 创建表及加载原始数据（E: extract）
		create table keyllo_log_201703(
			conetnt string
		);
		load xxx;

2. 数据预处理 （T: transafer）
		create table xxx AS select xxx
		python 
			输入 &gt;&gt; content
			|
			|regex
			|
			输出 &lt;&lt; ip,req_url,http_ref


3. 子表加载数据（L: load）
		load
</code></pre>

<p><br /></p>

<h3 id="用户自定义函数udf">用户自定义函数（UDF）</h3>

<p>UDF是用户自定义函数允许用户扩展HiveSQL的功能，具体有三种UDF（UDF、UDAF、UDTF）</p>

<ul>
  <li>UDF：一进一出</li>
  <li>UDAF：User Defined Aggregation Function，聚集函数，多进一出，类似于 count/min/max</li>
  <li>UDTF：User Defined Table-Generating Function，一进多出，如lateral view explore()</li>
</ul>

<p>下面以自定义一个转化小写函数进行说明：</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="c1">//1. 需要的jar包</span>
<span class="o">&lt;</span><span class="n">dependency</span><span class="o">&gt;</span>
  	<span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hive</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
  	<span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">hive</span><span class="o">-</span><span class="n">exec</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
  	<span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span><span class="err">$</span><span class="o">{</span><span class="n">hive</span><span class="o">.</span><span class="na">version</span><span class="o">}&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">dependency</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">dependency</span><span class="o">&gt;</span>
  	<span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hive</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
  	<span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">hive</span><span class="o">-</span><span class="n">jdbc</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
 	<span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span><span class="err">$</span><span class="o">{</span><span class="n">hive</span><span class="o">.</span><span class="na">version</span><span class="o">}&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">dependency</span><span class="o">&gt;</span>
  

<span class="c1">//2. 编码定义自己的UDF</span>
<span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">keyllo</span><span class="o">.</span><span class="na">hive</span><span class="o">.</span><span class="na">udf</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.hive.ql.exec.UDF</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.Text</span><span class="o">;</span>
<span class="cm">/**
 * 定义自己的Hive function
 *   [注意事项]  
 * 		a. UDF必须要有返回类型，可以返回null，但是返回类型不能是void 
 * 		b. UDF中常用mapreduce中的Text/LongWritable 等类型，不推荐使用java类型
 */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyLowerUDF</span> <span class="kd">extends</span> <span class="n">UDF</span> <span class="o">{</span>
	<span class="c1">// 继承UDF类，实现evaluate函数（支持重载）</span>
	<span class="kd">public</span> <span class="n">Text</span> <span class="nf">evaluate</span><span class="o">(</span><span class="n">Text</span> <span class="n">str</span><span class="o">)</span> <span class="o">{</span>
		<span class="k">if</span> <span class="o">(</span><span class="n">str</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
			<span class="k">return</span> <span class="kc">null</span><span class="o">;</span>
		<span class="o">}</span>
	<span class="k">return</span> <span class="k">new</span> <span class="nf">Text</span><span class="o">(</span><span class="n">str</span><span class="o">.</span><span class="na">toString</span><span class="o">().</span><span class="na">toLowerCase</span><span class="o">());</span>
<span class="o">}</span>
  
  
<span class="c1">//3. 将刚写的自定义函数打包上传到 本地 或 HDFS文件系统上，并在hive中注册使用自定义函数，使用函数</span>
<span class="c1">//方式一：(临时创建，企业中常用，一般放在脚本中执行)</span>
<span class="n">hive</span><span class="o">(</span><span class="n">db_hive_01</span><span class="o">)&gt;</span> <span class="n">add</span> <span class="n">jar</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">datas</span><span class="o">/</span><span class="n">test</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">hive</span><span class="o">-</span><span class="n">udf</span><span class="o">.</span><span class="na">jar</span><span class="o">;</span>
<span class="n">hive</span><span class="o">(</span><span class="n">db_hive_01</span><span class="o">)&gt;</span> <span class="n">create</span> <span class="n">temporary</span> <span class="n">function</span> <span class="n">my_lower1</span> <span class="n">as</span> <span class="err">'</span><span class="n">com</span><span class="o">.</span><span class="na">keyllo</span><span class="o">.</span><span class="na">hive</span><span class="o">.</span><span class="na">udf</span><span class="o">.</span><span class="na">MyLowerUDF</span><span class="err">'</span><span class="o">;</span>
<span class="n">hive</span><span class="o">(</span><span class="n">db_hive_01</span><span class="o">)&gt;</span> <span class="n">select</span> <span class="n">ename</span><span class="o">,</span><span class="n">my_lower1</span><span class="o">(</span><span class="n">ename</span><span class="o">)</span> <span class="n">lower_ename</span> <span class="n">from</span> <span class="n">emp</span> <span class="n">limit</span> <span class="mi">5</span><span class="o">;</span>

<span class="c1">//方式二：（永久创建，需要将jar包上传到HDFS文件系统）</span>
<span class="n">hive</span><span class="o">(</span><span class="n">db_hive_01</span><span class="o">)&gt;</span> <span class="n">create</span> <span class="n">function</span> <span class="n">my_lower2</span> <span class="n">as</span> <span class="err">'</span><span class="n">com</span><span class="o">.</span><span class="na">keyllo</span><span class="o">.</span><span class="na">hive</span><span class="o">.</span><span class="na">udf</span><span class="o">.</span><span class="na">MyLowerUDF</span><span class="err">'</span> <span class="n">using</span> <span class="n">jar</span> <span class="err">'</span><span class="nl">hdfs:</span><span class="c1">//ns1/user/ubuntu/lib/hive-udf.jar';</span>
<span class="n">hive</span><span class="o">(</span><span class="n">db_hive_01</span><span class="o">)&gt;</span> <span class="n">select</span> <span class="n">ename</span><span class="o">,</span><span class="n">my_lower2</span><span class="o">(</span><span class="n">ename</span><span class="o">)</span> <span class="n">lower_ename</span> <span class="n">from</span> <span class="n">emp</span> <span class="n">limit</span> <span class="mi">5</span><span class="o">;</span>
</code></pre>
</div>

<p><br /></p>

<h3 id="hiveserver2---beeline简介应用较少">hiveserver2  &amp; beeline简介（应用较少）</h3>

<blockquote>
  <p><strong>问题导读</strong></p>

  <p>1.hive允许远程客户端使用哪些编程语言？</p>

  <p>2.已经存在HiveServer为什么还需要HiveServer2？</p>

  <p>3.HiveServer2有哪些优点？</p>

  <p>4.hive.server2.thrift.min.worker.threads-最小工作线程数，默认为多少？</p>

  <p>5.启动Hiveserver2有哪两种方式？</p>
</blockquote>

<p>在之前的学习和实践Hive中，使用的都是CLI或者hive –e的方式，该方式仅允许使用HiveQL执行查询、更新等操作，并且该方式比较笨拙单一。幸好Hive提供了轻客户端的实现，通过HiveServer或者HiveServer2，客户端可以在不启动CLI的情况下对Hive中的数据进行操作，两者都允许远程客户端使用多种编程语言如Java、Python向Hive提交请求，取回结果。</p>

<p>HiveServer或者HiveServer2都是基于Thrift的，但HiveSever有时被称为Thrift server，而HiveServer2却不会。既然已经存在HiveServer为什么还需要HiveServer2呢？这是因为HiveServer不能处理多于一个客户端的并发请求，这是由于HiveServer使用的Thrift接口所导致的限制，不能通过修改HiveServer的代码修正。因此在Hive-0.11.0版本中重写了HiveServer代码得到了HiveServer2，进而解决了该问题。HiveServer2支持多客户端的并发和认证，为开放API客户端如JDBC、ODBC提供了更好的支持。</p>

<p>既然HiveServer2提供了更强大的功能，将会对其进行着重学习，但也会简单了解一下HiveServer的使用方法。在命令中输入hive –service help，结果如下。</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>bin/hive --service <span class="nb">help
</span>Usage ./hive &lt;parameters&gt; --service serviceName &lt;service parameters&gt;
Service List: beeline cli <span class="nb">help </span>hiveserver2 hiveserver hwi jar lineage metastore metatool orcfiledump rcfilecat schemaTool version 
Parameters parsed:
  --auxpath : Auxillary jars 
  --config : Hive configuration directory
  --service : Starts specific service/component. cli is default
Parameters used:
  HADOOP_HOME or HADOOP_PREFIX : Hadoop install directory
  HIVE_OPT : Hive options
For <span class="nb">help </span>on a particular service:
  ./hive --service serviceName --help
Debug <span class="nb">help</span>:  ./hive --debug --help

<span class="gp">$ </span>bin/hive --service hiveserver -help
Starting Hive Thrift Server
usage: hiveserver
 -h,--help                        Print <span class="nb">help </span>information
    --hiveconf &lt;<span class="nv">property</span><span class="o">=</span>value&gt;   Use value <span class="k">for </span>given property
    --maxWorkerThreads &lt;arg&gt;      maximum number of worker threads,
                                  default:2147483647
    --minWorkerThreads &lt;arg&gt;      minimum number of worker threads,
                                  default:100
 -p &lt;port&gt;                        Hive Server port number, default:10000
 -v,--verbose                     Verbose mode
 
<span class="c">#启动hiveserver服务，默认hiveserver运行在端口10000，最小100工作线程，最大2147483647工作线程。</span>
<span class="gp">$ </span>bin/hive --service hiveserver -v
Starting Hive Thrift Server
Starting hive server on port 10000 with 100 min worker threads and 2147483647 max worker threads
</code></pre>
</div>

<p><br /></p>

<p>接下来学习更强大的hiveserver2。Hiveserver2允许在配置文件hive-site.xml中进行配置管理，具体的参数为：</p>

<pre><code class="language-default">hive.server2.thrift.min.worker.threads – 最小工作线程数，默认为5。
hive.server2.thrift.max.worker.threads – 最小工作线程数，默认为500。
hive.server2.thrift.port – TCP 的监听端口，默认为10000。
hive.server2.thrift.bind.host – TCP绑定的主机，默认为localhost。
</code></pre>

<p>也可以设置环境变量HIVE_SERVER2_THRIFT_BIND_HOST和HIVE_SERVER2_THRIFT_PORT覆盖hive-site.xml设置的主机和端口号。从Hive-0.13.0开始，HiveServer2支持通过HTTP传输消息，该特性当客户端和服务器之间存在代理中介时特别有用。与HTTP传输相关的参数如下：</p>

<pre><code class="language-default">hive.server2.transport.mode – 默认值为binary（TCP），可选值HTTP。
hive.server2.thrift.http.port – HTTP的监听端口，默认值为10001。
hive.server2.thrift.http.path – 服务的端点名称，默认为 cliservice。
hive.server2.thrift.http.min.worker.threads – 服务池中的最小工作线程，默认为5。
hive.server2.thrift.http.max.worker.threads – 服务池中的最小工作线程，默认为500。
</code></pre>

<p>启动Hiveserver2有两种方式:</p>

<ul>
  <li>一种是上面已经介绍过的 bin/hive –service hiveserver2</li>
  <li>另一种更为简洁，为 bin/hiveserver2</li>
</ul>

<p>默认情况下，HiveServer2以提交查询的用户执行查询（true），如果hive.server2.enable.doAs设置为false，查询将以运行hiveserver2进程的用户运行。为了防止非加密模式下的内存泄露，可以通过设置下面的参数为true禁用文件系统的缓存：</p>

<pre><code class="language-default">fs.hdfs.impl.disable.cache – 禁用HDFS文件系统缓存，默认值为false。
fs.file.impl.disable.cache – 禁用本地文件系统缓存，默认值为false。
</code></pre>

<p><br /></p>

<p>简单使用hiveserver2：<a href="https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline–CommandLineShell">参考</a></p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 后台进程启动hiveserver2服务端</span>
<span class="gp">$ </span>bin/hiveserver2 &amp;


<span class="c"># 查看beeline帮助</span>
/beeline  --help

<span class="c"># 使用beeline连接hiveserver2服务</span>
<span class="gp">$ </span>bin/beeline
<span class="gp">&gt; </span>!connect jdbc:hive2://localhost:10000 ubuntu pwdxxx
<span class="gp">&gt; </span>...
0: jdbc:hive2://localhost:10000&gt; show databases;
+----------------+
| database_name  |
+----------------+
| db_hive_01     |
| default        |
+----------------+

<span class="c"># 或者使用beeline连接hiveserver2服务</span>
<span class="gp">$ </span>bin/beeline -u jdbc:hive2://localhost:10000/db_hive_01 -n ubuntu -p pwdxxx
</code></pre>
</div>

<p><br /></p>

<p>hiveserver2  jdbc 驱动使用：<a href="https://cwiki.apache.org/confluence/display/Hive/HiveServer2+Clients#HiveServer2Clients-Beeline–CommandLineShell">参考</a> , 通常使用hive的 <code class="highlighter-rouge">select *</code> 快速查询。</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">keyllo</span><span class="o">.</span><span class="na">hive</span><span class="o">.</span><span class="na">jdbc</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.sql.SQLException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.sql.Connection</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.sql.ResultSet</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.sql.Statement</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span><span class="o">;</span>
<span class="cm">/**
 * hiveserver2 jdbc的用途：
 * 		将分析的结果存储在hive结果表【数据量小】中，前端可以通过dao代码进行数据的查询 
 * hiveserver2的缺点：
 * 		并发性不好，企业中不常用
 */</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">HiveJdbcClient</span> <span class="o">{</span>
   	<span class="kd">private</span> <span class="kd">static</span> <span class="n">String</span> <span class="n">DRIVERNAME</span> <span class="o">=</span> <span class="s">"org.apache.hive.jdbc.HiveDriver"</span><span class="o">;</span>

   	<span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">SQLException</span> <span class="o">{</span>
    	<span class="k">try</span> <span class="o">{</span>
      		<span class="n">Class</span><span class="o">.</span><span class="na">forName</span><span class="o">(</span><span class="n">DRIVERNAME</span><span class="o">);</span>
    	<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">ClassNotFoundException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
      		<span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
      		<span class="n">System</span><span class="o">.</span><span class="na">exit</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
    	<span class="o">}</span>

    	<span class="c1">// get connection</span>
    	<span class="n">Connection</span> <span class="n">conn</span> <span class="o">=</span> <span class="n">DriverManager</span><span class="o">.</span>
          <span class="nf">getConnection</span><span class="o">(</span><span class="s">"jdbc:hive2://hadoop01:10000/db_hive_01"</span><span class="o">,</span> <span class="s">"ubuntu"</span><span class="o">,</span> <span class="s">"xxxxxx"</span><span class="o">);</span>


    	<span class="cm">/*
		//create table
		Statement stmt = conn.createStatement();
		String tableName = "dept";
		stmt.execute("drop table if exists " + tableName);
		stmt.execute("create table " + tableName + " (deptno int, dname string, loc string)");

		// show tables
		String sql = "show tables '" + tableName + "'";
		System.out.println("Running: " + sql);
		ResultSet res = stmt.executeQuery(sql);
		if (res.next()) {
			System.out.println(res.getString(1));
		}

		// describe table
		sql = "describe " + tableName;
		System.out.println("Running: " + sql);
		res = stmt.executeQuery(sql);
		while (res.next()) {
        	System.out.println(res.getString(1) + "\t" + res.getString(2));
		}

		// load data into table
		// NOTE: filepath has to be local to the hive server
		// NOTE: '/opt/datas/test/datatap/db_hive_01_dept.txt' is a ctrl-A separated file with two fields per line
		String filepath = "/opt/datas/test/datatap/db_hive_01_dept.txt";
		sql = "load data local inpath '" + filepath + "' into table " + tableName;
		System.out.println("Running: " + sql);
		stmt.execute(sql);
		*/</span>

   	 	<span class="c1">// select * query</span>
    	<span class="n">Statement</span> <span class="n">stmt</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="na">createStatement</span><span class="o">();</span>
    	<span class="n">String</span> <span class="n">tableName</span> <span class="o">=</span> <span class="s">"dept"</span><span class="o">;</span>		
    	<span class="n">String</span> <span class="n">sql</span> <span class="o">=</span> <span class="s">"select * from "</span> <span class="o">+</span> <span class="n">tableName</span><span class="o">;</span>
    	<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Running: "</span> <span class="o">+</span> <span class="n">sql</span><span class="o">);</span>
    	<span class="n">ResultSet</span> <span class="n">res</span> <span class="o">=</span> <span class="n">stmt</span><span class="o">.</span><span class="na">executeQuery</span><span class="o">(</span><span class="n">sql</span><span class="o">);</span>
    	<span class="k">while</span> <span class="o">(</span><span class="n">res</span><span class="o">.</span><span class="na">next</span><span class="o">())</span> <span class="o">{</span>
      		<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">String</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">res</span><span class="o">.</span><span class="na">getInt</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span> <span class="o">+</span> <span class="s">"\t"</span> <span class="o">+</span> <span class="n">res</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="mi">2</span><span class="o">));</span>
    	<span class="o">}</span>

    	<span class="c1">// regular hive query</span>
    	<span class="n">sql</span> <span class="o">=</span> <span class="s">"select count(1) from "</span> <span class="o">+</span> <span class="n">tableName</span><span class="o">;</span>
    	<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Running: "</span> <span class="o">+</span> <span class="n">sql</span><span class="o">);</span>
    	<span class="n">res</span> <span class="o">=</span> <span class="n">stmt</span><span class="o">.</span><span class="na">executeQuery</span><span class="o">(</span><span class="n">sql</span><span class="o">);</span>
    	<span class="k">while</span> <span class="o">(</span><span class="n">res</span><span class="o">.</span><span class="na">next</span><span class="o">())</span> <span class="o">{</span>
      		<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">res</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="mi">1</span><span class="o">));</span>
    	<span class="o">}</span>
  	<span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<p><br /></p>

<h3 id="hive-常见数据压缩技术">hive 常见数据压缩技术</h3>

<p>常见的压缩格式：</p>

<pre><code class="language-default">压缩格式：  bzip2、gzip、lzo、snappy     等，推荐使用snappy(谷歌开源)
压缩比：    bzip2 &gt; gzip &gt; lzo          bzip2最节省存储空间
解压缩速度： bzip2 &lt; gzip &lt; lzo		   lzo解压缩速度是最快的
</code></pre>

<p>数据压缩的好处：</p>

<ul>
  <li>
    <p>减少节点的io负载</p>
  </li>
  <li>
    <p>节省网络带宽</p>
  </li>
  <li>
    <p>提高整个job的性能</p>
  </li>
  <li>
    <p>压缩格式必须具有可分割性（hdfs block决定的）</p>

    <div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 查看hdfs支持的压缩格式</span>
sudo apt-get install libssl-dev
<span class="nv">$HADOOP_HOME</span>/bin/hadoop checknative
</code></pre>
    </div>

    <p>​</p>
  </li>
</ul>

<p><img src="http://img.blog.csdn.net/20170825185916047?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQva2luZ2x5am4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" style="width:80%" /></p>

<p><br /></p>


                    <hr>
                    <div class="row">
                        <div class="col-md-6">
                                <h5 style="display: inline;">Tags:</h5>
                                
                                    <button class="btn btn-white btn-xs" type="button">java</button>
                                
                        </div>
                        
                        <!--
                        <div class="col-md-6">
                            <div class="small text-right">
                                <div>    
                                    <i class="fa fa-comments-o"> </i> 
                                    <span class="ds-comments">0</span>条评论
                                </div>
                                <div>
                                    <i class="fa fa-share-alt"> </i> 
                                    <span class="ds-shares">0</span>条转发
                                </div>  
                            </div>
                        </div>
                        -->
                    </div>
                    <br>
                    <div class="row">
                        <div class="col-lg-12">
                            <!-- donate -->
                            
                                <button type="button" class="btn btn-primary" data-toggle="modal" data-target="#myModal2">
    Donate
</button>
<div class="modal inmodal" id="myModal2" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content animated flipInY">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title">Donate Me</h4>
                <small class="font-bold">Thanks for your support!</small>
            </div>
            <div class="modal-body">
                <div class="tabbable" id="tabs-960227">
                    <ul class="nav nav-tabs">
                        <li class="active">
                            <a href="#panel-405278" data-toggle="tab">Alipay</a>
                        </li>
                        <li>
                            <a href="#panel-874705" data-toggle="tab">Wechat</a>
                        </li>
                    </ul>
                    <div class="tab-content">
                        <div class="tab-pane active" id="panel-405278">
                            <div class="text-center">
                                <img src="/static/img/pay/alipay.png"" height="250" width="250">
                            </div>    
                        </div>
                        <div class="tab-pane" id="panel-874705">
                            <div class="text-center">
                                <img src="/static/img/pay/wechat.png"" height="250" width="250">
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-white" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

                            
                            <br>
                            <!-- share -->
                            
                                
<!--分享-->
<div class="row" style="margin-top:30px;">
	<h2>Share:</h2>
    <div class="social-share" style="margin-left:-5px;"data-sites="wechat,qq,qzone,weibo"></div> 
</div>
<link rel="stylesheet" href="/static/css/share.min.css">
<script src="/static/js/jquery.share.min.js"></script>
<script src="/static/js/embed.js"></script>

<script>
  var url = 'http://localhost:4000/java/2017/08/08/java-hive-01.html';
  var source = 'http://localhost:4000/java/2017/08/08/java-hive-01.html';
  var title = 'hive的基本简介及安装、配置、使用（一）';
  var excerpt = $("p:eq(0)").text();
  
  var imageUrl = 'http://localhost:4000/static/img/landing/header_one.jpg';
  var imgEle = $(".content_img:eq(0)");
  if (imgEle) {
    imageUrl = imgEle.attr("src");
  }

  var $config = {
      url: url, // 网址，默认使用 window.location.href
      source: source, // 来源（QQ空间会用到）, 默认读取head标签：<meta name="site" content="http://overtrue" />
      title: title, // 标题，默认读取 document.title 或者 <meta name="title" content="share.js" />
      description: excerpt, // 描述, 默认读取head标签：<meta name="description" content="PHP弱类型的实现原理分析" />
      image: imageUrl, // 图片, 默认取网页中第一个img标签
      sites: ['qzone', 'qq', 'weibo','wechat','douban'], // 启用的站点
      //disabled: ['google', 'facebook', 'twitter'], // 禁用的站点
      wechatQrcodeTitle: "微信扫一扫：分享", // 微信二维码提示文字
      wechatQrcodeHelper: '<p style="font-size:10px;">微信里点“发现”，扫一下</p><p style="font-size:10px;">二维码便可将本文分享至朋友圈。</p>',
   };
  $('.social-share').share($config);
</script>




                            
                            <br>
                            <!-- comment -->
                            <!--



-->

<!-- 多说评论框 start -->
<div class="row" style="margin-top:25px;"></div>
<div class="ds-thread" data-thread-key="/java/2017/08/08/java-hive-01.html" data-title="hive的基本简介及安装、配置、使用（一）" data-url="http://localhost:4000/java/2017/08/08/java-hive-01.html"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
	var duoshuoQuery = {short_name:"kinglyjn"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
</script>
<!-- 多说公共JS代码 end -->



                        </div>
                    </div>

                </div>
            </div>
        </div>
    </div>

</div>



	
	    <script src="/static/js/scroll.js"></script>

<!-- Baidu analytics -->


<!-- Google analytics -->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-73784599-1', 'auto');
    ga('send', 'pageview');

  </script>


<!--

-->

<!--

-->

<script async src="/static/js/count_page.js"></script>

	

</body>
</html>